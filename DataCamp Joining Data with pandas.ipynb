{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2264f1d-222b-4a79-b8a3-8b5f1fd0115b",
   "metadata": {},
   "source": [
    "## Joining Data with pandas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b0a85-3480-4c2b-8f3c-180fe6f5b194",
   "metadata": {},
   "source": [
    "## Course Description\n",
    "\n",
    "Being able to combine and work with multiple datasets is an essential skill for any aspiring Data Scientist. Pandas is a crucial cornerstone of the Python data science ecosystem, with Stack Overflow recording 5 million views for pandas questions. Learn to handle multiple DataFrames by combining, organizing, joining, and reshaping them using pandas. You'll work with datasets from the World Bank and the City Of Chicago. You will finish the course with a solid skillset for data-joining in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac21d26-0b93-4127-ba38-242cb56f3dd2",
   "metadata": {},
   "source": [
    "##  Data Merging Basics\n",
    "Free\n",
    "0%\n",
    "\n",
    "Learn how you can merge disparate data using inner joins. By combining information from multiple sources you’ll uncover compelling insights that may have previously been hidden. You’ll also learn how the relationship between those sources, such as one-to-one or one-to-many, can affect your result.\n",
    "\n",
    "    Inner join    50 xp\n",
    "    What column to merge on?    50 xp\n",
    "    Your first inner join    100 xp\n",
    "    Inner joins and number of rows returned    100 xp\n",
    "    One-to-many relationships    50 xp\n",
    "    One-to-many classification    100 xp\n",
    "    One-to-many merge    100 xp\n",
    "    Merging multiple DataFrames    50 xp\n",
    "    Total riders in a month    100 xp\n",
    "    Three table merge    100 xp\n",
    "    One-to-many merge with multiple tables    100 xp \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890ade1-e66a-46c5-a8ef-f4c96f8cff86",
   "metadata": {},
   "source": [
    "##  Merging Tables With Different Join Types\n",
    "0%\n",
    "\n",
    "Take your knowledge of joins to the next level. In this chapter, you’ll work with TMDb movie data as you learn about left, right, and outer joins. You’ll also discover how to merge a table to itself and merge on a DataFrame index.\n",
    "\n",
    "    Left join    50 xp\n",
    "    Counting missing rows with left join    100 xp\n",
    "    Enriching a dataset    100 xp\n",
    "    How many rows with a left join?    50 xp\n",
    "    Other joins    50 xp\n",
    "    Right join to find unique movies    100 xp\n",
    "    Popular genres with right join    100 xp\n",
    "    Using outer join to select actors    100 xp\n",
    "    Merging a table to itself    50 xp\n",
    "    Self join    100 xp\n",
    "    How does pandas handle self joins?    50 xp\n",
    "    Merging on indexes    50 xp\n",
    "    Index merge for movie ratings    100 xp\n",
    "    Do sequels earn more?    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a2a0c-02ec-48ba-9e77-74d4cdba100c",
   "metadata": {},
   "source": [
    "##  Advanced Merging and Concatenating\n",
    "0%\n",
    "\n",
    "In this chapter, you’ll leverage powerful filtering techniques, including semi-joins and anti-joins. You’ll also learn how to glue DataFrames by vertically combining and using the pandas.concat function to create new datasets. Finally, because data is rarely clean, you’ll also learn how to validate your newly combined data structures.\n",
    "\n",
    "    Filtering joins    50 xp\n",
    "    Steps of a semi-join    100 xp\n",
    "    Performing an anti-join    100 xp\n",
    "    Performing a semi-join    100 xp\n",
    "    Concatenate DataFrames together vertically    50 xp\n",
    "    Concatenation basics    100 xp\n",
    "    Concatenating with keys    100 xp\n",
    "    Using the append method    100 xp\n",
    "    Verifying integrity    50 xp\n",
    "    Validating a merge    50 xp\n",
    "    Concatenate and merge to find common songs    100 xp \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5d283-f26c-4a58-966c-bf76786dc601",
   "metadata": {},
   "source": [
    "##  Merging Ordered and Time-Series Data\n",
    "0%\n",
    "\n",
    "In this final chapter, you’ll step up a gear and learn to apply pandas' specialized methods for merging time-series and ordered data together with real-world financial and economic data from the city of Chicago. You’ll also learn how to query resulting tables using a SQL-style format, and unpivot data using the melt method.\n",
    "\n",
    "    Using merge_ordered()    50 xp\n",
    "    Correlation between GDP and S&P500    100 xp\n",
    "    Phillips curve using merge_ordered()    100 xp\n",
    "    merge_ordered() caution, multiple columns    100 xp\n",
    "    Using merge_asof()    50 xp\n",
    "    Using merge_asof() to study stocks    100 xp\n",
    "    Using merge_asof() to create dataset    100 xp\n",
    "    merge_asof() and merge_ordered() differences    100 xp\n",
    "    Selecting data with .query()    50 xp\n",
    "    Explore financials with .query()    50 xp\n",
    "    Subsetting rows with .query()    100 xp\n",
    "    Reshaping data with .melt()    50 xp\n",
    "    Select the right .melt() arguments    50 xp\n",
    "    Using .melt() to reshape government data    100 xp\n",
    "    Using .melt() for stocks vs bond performance    100 xp\n",
    "    Course wrap-up    50 xp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3548aae-3caa-4992-86c3-e09699472764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "232283a8-955a-4843-aea5-1453bbd38fe6",
   "metadata": {},
   "source": [
    "## Inner join\n",
    "\n",
    "\n",
    "\n",
    "**The Pandas package is a powerful tool for manipulating and transforming a in Python.  However, when working on an analysis, the data needed could be in multiple tables.  This course will focus on the vital skill of merging tables together.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# As we start, two quick clarifications.  \n",
    "\n",
    "First, through other courses on DataCamp, you may have learned how to import tabular data as DataFrame.  In this course, you may hear the words table and DataFrame, but they are equivalent here.  \n",
    "\n",
    "Second, we will refer to combingning different tables together as merging tales, but note that some refer to this same process as joining.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To help us learn about merging tables, we will use data from the city of Chicago data portal.  The city of Chicago is divided into fifty local neighborhoods called wards.  We have a table with data about the local goverment offices in each ward.  \n",
    "\n",
    "In this example, we want to merge the local government data with census data about the population of each ward.  If we look at the wards table, we have information about the local goverment of each ward, such as the goverment office address.  The census table contains the population of each ward in 2000 and 2010, and that change as percentage.  Additionally, it includes the address for the center of each ward.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "The two tables are related by their ward column.  We can merge them together, matching the ward number from each row of the ward table to the ward number from the census table.  \n",
    "\n",
    "**The Pandas package has an excellent DataFrame method for performing this type of merge called .merge() method.  The .merge() method takes the first DF and merges it with the second DF.  We use on= argument to tell it we want to merge the 2 DFs on the ward column.  Since we listed the ward table first, its columns will appear first in the output, followed by the columns from the second census table.  By default, it returns the rows have matching values for the on=column in both tables.  This is called an inner join.  \n",
    "\n",
    "An inner join will only return rows that have matching values in both tables.  \n",
    "\n",
    "**You may have noticed that the merged table has columns with suffixes of underscore x or y.  This is because both wards and census tables contained address and zip columns.  To avoid multiple columns with the same name, they are automatically given a suffix by the merge method.  We can use the suffix= argument of the .merge() to control this behavior.  We provide a tuple where all of the overlapping columns in the left table are given the suffix '_ward', and those of the right table will be given the suffix '_cen'.  This makes it easier for us to tell the difference between the columns.   \n",
    "\n",
    "\n",
    "\n",
    "wards = pd.read_csv('Ward_Offices.csv')\n",
    "print(wards.head())\n",
    "print(wards.shape)\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "  ward            alderman                          address    zip\n",
    "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
    "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
    "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
    "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
    "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n",
    "\n",
    "(50, 4)\n",
    "\n",
    "\n",
    "census = pd.read_csv('Ward_Census.csv')\n",
    "print(census.head())\n",
    "print(census.shape)\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "  ward  pop_2000  pop_2010 change                                  address    zip  \n",
    "0    1     52951     56149     6%              2765 WEST SAINT MARY STREET  60647  \n",
    "1    2     54361     55805     3%                 WM WASTE MANAGEMENT 1500  60622  \n",
    "2    3     40385     53039    31%                      17 EAST 38TH STREET  60653  \n",
    "3    4     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL  60653  \n",
    "4    5     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE  60637\n",
    "\n",
    "(50,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0ea7a9-46df-45cc-a459-7429e5d57145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ward            alderman                          address    zip\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n",
      "(50, 4)\n",
      "  ward  pop_2000  pop_2010 change                                  address  \\\n",
      "0    1     52951     56149     6%              2765 WEST SAINT MARY STREET   \n",
      "1    2     54361     55805     3%                 WM WASTE MANAGEMENT 1500   \n",
      "2    3     40385     53039    31%                      17 EAST 38TH STREET   \n",
      "3    4     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL   \n",
      "4    5     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE   \n",
      "\n",
      "     zip  \n",
      "0  60647  \n",
      "1  60622  \n",
      "2  60653  \n",
      "3  60653  \n",
      "4  60637  \n",
      "(50, 6)\n",
      "  ward            alderman                        address_x  zip_x  pop_2000  \\\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647     52951   \n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622     54361   \n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609     40385   \n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616     51953   \n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649     55302   \n",
      "\n",
      "   pop_2010 change                                address_y  zip_y  \n",
      "0     56149     6%              2765 WEST SAINT MARY STREET  60647  \n",
      "1     55805     3%                 WM WASTE MANAGEMENT 1500  60622  \n",
      "2     53039    31%                      17 EAST 38TH STREET  60653  \n",
      "3     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL  60653  \n",
      "4     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE  60637  \n",
      "50\n",
      "  ward            alderman                     address_ward zip_ward  \\\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE    60647   \n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE    60622   \n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET    60609   \n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR    60616   \n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET    60649   \n",
      "\n",
      "   pop_2000  pop_2010 change                              address_cen zip_cen  \n",
      "0     52951     56149     6%              2765 WEST SAINT MARY STREET   60647  \n",
      "1     54361     55805     3%                 WM WASTE MANAGEMENT 1500   60622  \n",
      "2     40385     53039    31%                      17 EAST 38TH STREET   60653  \n",
      "3     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL   60653  \n",
      "4     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE   60637  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "ward = pd.read_pickle('ward.p')\n",
    "census = pd.read_pickle('census.p')\n",
    "\n",
    "\n",
    "print(ward.head())\n",
    "print(ward.shape)\n",
    "\n",
    "print(census.head())\n",
    "print(census.shape)\n",
    "\n",
    "\n",
    "\n",
    "merged_df = ward.merge(census, how='inner', on='ward')\n",
    "#print(help(pd.merge))\n",
    "print(merged_df.head())\n",
    "print(len(merged_df))\n",
    "\n",
    "\n",
    "merged_df2 = ward.merge(census, how='inner', on='ward', suffixes=('_ward', '_cen'))\n",
    "print(merged_df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296a90a-2510-4b6c-bb3c-8b233ff517c1",
   "metadata": {},
   "source": [
    "## What column to merge on?\n",
    "\n",
    "Chicago provides a list of taxicab owners and vehicles licensed to operate within the city, for public safety. Your goal is to merge two tables together. One table is called taxi_owners, with info about the taxi cab company owners, and one is called taxi_veh, with info about each taxi cab vehicle. Both the taxi_owners and taxi_veh tables have been loaded for you and you can explore them in the IPython shell.\n",
    "\n",
    "Choose the column you would use to merge the two tables on using the .merge() method.\n",
    "Instructions\n",
    "50 XP\n",
    "Possible Answers\n",
    "\n",
    "#    on='rid'\n",
    "    on='vid'\n",
    "    on='year'\n",
    "    on='zip'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0796c-b9bd-434d-bc85-a9c7ac0c27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [1]:\n",
    "print(taxi_owners.head())\n",
    "     rid   vid           owner                 address    zip\n",
    "0  T6285  6285  AGEAN TAXI LLC     4536 N. ELSTON AVE.  60630\n",
    "1  T4862  4862    MANGIB CORP.  5717 N. WASHTENAW AVE.  60659\n",
    "2  T1495  1495   FUNRIDE, INC.     3351 W. ADDISON ST.  60618\n",
    "3  T4231  4231    ALQUSH CORP.   6611 N. CAMPBELL AVE.  60645\n",
    "4  T5971  5971  EUNIFFORD INC.     3351 W. ADDISON ST.  60618\n",
    "In [2]:\n",
    "print(taxi_veh.head())\n",
    "    vid    make   model  year fuel_type                owner\n",
    "0  2767  TOYOTA   CAMRY  2013    HYBRID       SEYED M. BADRI\n",
    "1  1411  TOYOTA    RAV4  2017    HYBRID          DESZY CORP.\n",
    "2  6500  NISSAN  SENTRA  2019  GASOLINE       AGAPH CAB CORP\n",
    "3  2746  TOYOTA   CAMRY  2013    HYBRID  MIDWEST CAB CO, INC\n",
    "4  5922  TOYOTA   CAMRY  2013    HYBRID       SUMETTI CAB CO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad795c-7f13-4c62-ba35-9d31af6ace87",
   "metadata": {},
   "source": [
    "## Your first inner join\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# You have been tasked with figuring out what the most popular types of fuel used in Chicago taxis are. \n",
    "To complete the analysis, you need to merge the taxi_owners and taxi_veh tables together on the vid column. You can then use the merged table along with the .value_counts() method to find the most common fuel_type.\n",
    "\n",
    "Since you'll be working with pandas throughout the course, the package will be preloaded for you as pd in each exercise in this course. Also the taxi_owners and taxi_veh DataFrames are loaded for you.\n",
    "Instructions 1/3\n",
    "100 XP\n",
    "\n",
    "    Question 1\n",
    "    Merge taxi_owners with taxi_veh on the column vid, and save the result to taxi_own_veh.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    Set the left and right table suffixes for overlapping columns of the merge to _own and _veh, respectively.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 3\n",
    "#    Select the fuel_type column from taxi_own_veh and print the value_counts() to find the most popular fuel_types used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a580ff-d068-49de-90ca-35da92053b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    vid    make   model  year fuel_type                owner\n",
      "0  2767  TOYOTA   CAMRY  2013    HYBRID       SEYED M. BADRI\n",
      "1  1411  TOYOTA    RAV4  2017    HYBRID          DESZY CORP.\n",
      "2  6500  NISSAN  SENTRA  2019  GASOLINE       AGAPH CAB CORP\n",
      "3  2746  TOYOTA   CAMRY  2013    HYBRID  MIDWEST CAB CO, INC\n",
      "4  5922  TOYOTA   CAMRY  2013    HYBRID       SUMETTI CAB CO\n",
      "     rid   vid           owner                 address    zip\n",
      "0  T6285  6285  AGEAN TAXI LLC     4536 N. ELSTON AVE.  60630\n",
      "1  T4862  4862    MANGIB CORP.  5717 N. WASHTENAW AVE.  60659\n",
      "2  T1495  1495   FUNRIDE, INC.     3351 W. ADDISON ST.  60618\n",
      "3  T4231  4231    ALQUSH CORP.   6611 N. CAMPBELL AVE.  60645\n",
      "4  T5971  5971  EUNIFFORD INC.     3351 W. ADDISON ST.  60618\n",
      "     rid   vid       owner_own                 address    zip    make   model  \\\n",
      "0  T6285  6285  AGEAN TAXI LLC     4536 N. ELSTON AVE.  60630  NISSAN  ALTIMA   \n",
      "1  T4862  4862    MANGIB CORP.  5717 N. WASHTENAW AVE.  60659   HONDA     CRV   \n",
      "2  T1495  1495   FUNRIDE, INC.     3351 W. ADDISON ST.  60618  TOYOTA  SIENNA   \n",
      "3  T4231  4231    ALQUSH CORP.   6611 N. CAMPBELL AVE.  60645  TOYOTA   CAMRY   \n",
      "4  T5971  5971  EUNIFFORD INC.     3351 W. ADDISON ST.  60618  TOYOTA  SIENNA   \n",
      "\n",
      "   year fuel_type       owner_veh  \n",
      "0  2011    HYBRID  AGEAN TAXI LLC  \n",
      "1  2014  GASOLINE    MANGIB CORP.  \n",
      "2  2015  GASOLINE   FUNRIDE, INC.  \n",
      "3  2014    HYBRID    ALQUSH CORP.  \n",
      "4  2015  GASOLINE  EUNIFFORD INC.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuel_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COMPRESSED NATURAL GAS</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLEX FUEL</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GASOLINE</th>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYBRID</th>\n",
       "      <td>2792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         vid\n",
       "fuel_type                   \n",
       "COMPRESSED NATURAL GAS    27\n",
       "FLEX FUEL                 89\n",
       "GASOLINE                 611\n",
       "HYBRID                  2792"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "taxi_veh = pd.read_pickle('taxi_vehicles.p')\n",
    "taxi_owners = pd.read_pickle('taxi_owners.p')\n",
    "\n",
    "\n",
    "print(taxi_veh.head())\n",
    "print(taxi_owners.head())\n",
    "\n",
    "\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', how='inner', suffixes=('_own', '_veh'))\n",
    "print(taxi_own_veh.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "taxi_own_veh.pivot_table(values='vid', index='fuel_type', aggfunc=lambda x: len(x.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6cf34e-0dc9-4863-92c3-784431260e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2792\n"
     ]
    }
   ],
   "source": [
    "hyb_group = taxi_own_veh[taxi_own_veh['fuel_type']=='HYBRID'].copy()\n",
    "\n",
    "print(len(hyb_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "254698cb-20b6-4f46-8dd4-1d7224f1d5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID                    2792\n",
      "GASOLINE                   611\n",
      "FLEX FUEL                   89\n",
      "COMPRESSED NATURAL GAS      27\n",
      "Name: fuel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own','_veh'))\n",
    "\n",
    "\n",
    "\n",
    "# Print the value_counts to find the most popular fuel_type\n",
    "print(taxi_own_veh['fuel_type'].value_counts())\n",
    "\n",
    "\n",
    "# ***************************************************************************************************************** #\n",
    "# This approach is much simple than my code above with pivot_table and lambda expression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb91716-ca4c-4875-a32a-91458370be84",
   "metadata": {},
   "source": [
    "# *******************************************************************************************************************\n",
    "\n",
    "To count the dogs of each breed, we'll subset the breed column and use the .value_counts() method.  We can also use the sort= argument to get the breeds with biggest counts on top.  Also the normalize= argument can be used to turn the counts into proportions of the total.\n",
    "\n",
    "\n",
    "# We learned that in DataCamp Data Manipulation with Pandas course\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0cca2-a59c-4ffa-863b-35f4be73d0b6",
   "metadata": {},
   "source": [
    "## Inner joins and number of rows returned\n",
    "\n",
    "All of the merges you have studied to this point are called inner joins.  It is necessary to understand that inner joins only return the rows with matching values in both tables.  You will explore this further by reviewing the merge between the wards and census tables, then comparing it to merges of copies of these tables that are slightly altered, named wards_altered, and census_altered.  The first row of the wards column has been changed in the altered tables.  You will examine how this affects the merge between them. The tables have been loaded for you.\n",
    "\n",
    "For this exercise, it is important to know that the wards and census tables start with 50 rows.\n",
    "Instructions 1/3\n",
    "35 XP\n",
    "\n",
    "    Question 1\n",
    "    Merge wards and census on the ward column and save the result to wards_census.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    Merge the wards_altered and census tables on the ward column, and notice the difference in returned rows.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 3\n",
    "    Merge the wards and census_altered tables on the ward column, and notice the difference in returned rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "588e6168-6403-412e-a306-87503fcced26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ward            alderman                          address    zip\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n",
      "  ward  pop_2000  pop_2010 change                                  address  \\\n",
      "0    1     52951     56149     6%              2765 WEST SAINT MARY STREET   \n",
      "1    2     54361     55805     3%                 WM WASTE MANAGEMENT 1500   \n",
      "2    3     40385     53039    31%                      17 EAST 38TH STREET   \n",
      "3    4     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL   \n",
      "4    5     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE   \n",
      "\n",
      "     zip  \n",
      "0  60647  \n",
      "1  60622  \n",
      "2  60653  \n",
      "3  60653  \n",
      "4  60637  \n"
     ]
    }
   ],
   "source": [
    "print(ward.head())\n",
    "print(census.head())\n",
    "\n",
    "\n",
    "\n",
    "wards_census = ward.merge(census, on='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609b67b-bc38-4dbb-9f6e-1a46e9bca369",
   "metadata": {},
   "outputs": [],
   "source": [
    "wards_altered\n",
    "\n",
    "   ward                   alderman                            address    zip\n",
    "0    61         Proco \"Joe\" Moreno          2058 NORTH WESTERN AVENUE  60647\n",
    "1     2              Brian Hopkins         1400 NORTH  ASHLAND AVENUE  60622\n",
    "2     3                 Pat Dowell            5046 SOUTH STATE STREET  60609\n",
    "3     4           William D. Burns    435 EAST 35TH STREET, 1ST FLOOR  60616\n",
    "4     5         Leslie A. Hairston              2325 EAST 71ST STREET  60649\n",
    "5     6         Roderick T. Sawyer   8001 S. MARTIN LUTHER KING DRIVE  60619\n",
    "6     7        Gregory I. Mitchell              2249 EAST 95TH STREET  60617\n",
    "7     8         Michelle A. Harris    8539 SOUTH COTTAGE GROVE AVENUE  60619\n",
    "8     9           Anthony A. Beale                34 EAST 112TH PLACE  60628\n",
    "9    10      Susan Sadlowski Garza           10500 SOUTH EWING AVENUE  60617\n",
    "10   11     Patrick Daley Thompson          3659 SOUTH HALSTED STREET  60609\n",
    "11   12            George Cardenas           3476 SOUTH ARCHER AVENUE  60608\n",
    "12   13                Marty Quinn            6500 SOUTH PULASKI ROAD  60629\n",
    "13   14            Edward M. Burke              2650 WEST 51ST STREET  60632\n",
    "14   15           Raymond A. Lopez              1650 WEST 63RD STREET  60636\n",
    "15   16            Toni L. Foulkes              3045 WEST 63RD STREET  60629\n",
    "16   17             David H. Moore          7313 SOUTH ASHLAND AVENUE  60636\n",
    "17   18          Derrick G. Curtis            8359 SOUTH PULASKI ROAD  60652\n",
    "18   19          Matthew J. O'Shea         10400 SOUTH WESTERN AVENUE  60643\n",
    "19   20          Willie B. Cochran    6357 SOUTH COTTAGE GROVE AVENUE  60637\n",
    "20   21    Howard B. Brookins, Jr.  9011 SOUTH ASHLAND AVENUE, UNIT B  60620\n",
    "21   22              Ricardo Munoz        2500 SOUTH ST. LOUIS AVENUE  60623\n",
    "22   23        Michael R. Zalewski           6247 SOUTH ARCHER AVENUE  60638\n",
    "23   24         Michael Scott, Jr.           1158 SOUTH KEELER AVENUE  60624\n",
    "24   25       Daniel \"Danny\" Solis      1800 SOUTH BLUE ISLAND AVENUE  60608\n",
    "25   26          Roberto Maldonado          2511 WEST DIVISION STREET  60622\n",
    "26   27        Walter Burnett, Jr.             4 NORTH WESTERN AVENUE  60612\n",
    "27   28             Jason C. Ervin              2602 WEST 16TH STREET  60612\n",
    "28   29           Chris Taliaferro             6272 WEST NORTH AVENUE  60639\n",
    "29   30          Ariel E. Reyboras        3559 NORTH MILWAUKEE AVENUE  60641\n",
    "30   31  Milagros \"Milly\" Santiago            2521 NORTH PULASKI ROAD  60639\n",
    "31   32           Scott Waguespack         2657 NORTH CLYBOURN AVENUE  60614\n",
    "32   33               Deborah Mell         3001 WEST IRVING PARK ROAD  60618\n",
    "33   34           Carrie M. Austin              507 WEST 111TH STREET  60628\n",
    "34   35        Carlos Ramirez-Rosa           2710 NORTH SAWYER AVENUE  60647\n",
    "35   36           Gilbert Villegas                 6934 WEST DIVERSEY  60607\n",
    "36   37              Emma M. Mitts           4924 WEST CHICAGO AVENUE  60651\n",
    "37   38           Nicholas Sposato          3821  NORTH HARLEM AVENUE  60634\n",
    "38   39           Margaret Laurino          4404 WEST LAWRENCE AVENUE  60630\n",
    "39   40        Patrick J. O'Connor          5850 NORTH LINCOLN AVENUE  60659\n",
    "40   41      Anthony V. Napolitano           7442 NORTH HARLEM AVENUE  60631\n",
    "41   42             Brendan Reilly   325 WEST HURON STREET, SUITE 510  60654\n",
    "42   43             Michelle Smith          2523 NORTH HALSTED STREET  60614\n",
    "43   44                 Tom Tunney        3223 NORTH SHEFFIELD AVENUE  60657\n",
    "44   45              John S. Arena        4754 NORTH MILWAUKEE AVENUE  60630\n",
    "45   46            James Cappleman         4544 NORTH BROADWAY AVENUE  60640\n",
    "46   47                Ameya Pawar          4243 NORTH LINCOLN AVENUE  60618\n",
    "47   48             Harry Osterman         5533 NORTH BROADWAY AVENUE  60640\n",
    "48   49                  Joe Moore        7356 NORTH GREENVIEW AVENUE  60626\n",
    "49   50       Debra L. Silverstein    2949 WEST DEVON AVENUE, SUITE A  60659\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "census_altered\n",
    "\n",
    "ward  pop_2000  pop_2010 change                                            address    zip\n",
    "None     52951     56149     6%                        2765 WEST SAINT MARY STREET  60647\n",
    "   2     54361     55805     3%                           WM WASTE MANAGEMENT 1500  60622\n",
    "   3     40385     53039    31%                                17 EAST 38TH STREET  60653\n",
    "   4     51953     54589     5%            31ST ST HARBOR BUILDING LAKEFRONT TRAIL  60653\n",
    "   5     55302     51455    -7%            JACKSON PARK LAGOON SOUTH CORNELL DRIVE  60637\n",
    "   6     54989     52341    -5%                               150 WEST 74TH STREET  60636\n",
    "   7     54593     51581    -6%                          8549 SOUTH OGLESBY AVENUE  60617\n",
    "   8     54039     51687    -4%                         1346-1352 EAST 75TH STREET  60649\n",
    "   9     52008     51519    -1%                 11039-11059 SOUTH WENTWORTH AVENUE  60628\n",
    "  10     56613     51535    -9%                               10534 SOUTH AVENUE F  46394\n",
    "  11     64228     51497   -20%                            943-947 WEST 14TH PLACE  60607\n",
    "  12     68922     52235   -24%                         CP 46 STEVENSON EXPRESSWAY  60632\n",
    "  13     64382     53722   -17%                    SOUTH RAMP SOUTH LARAMIE AVENUE  60638\n",
    "  14     80143     54031   -33%                              4540 WEST 51ST STREET  60632\n",
    "  15     56057     51501    -8%    CHICAGO FIRE DEPARTMENT ENGINE COMPANY 123 2215  60632\n",
    "  16     50205     51954     3%                             6036 SOUTH WOOD STREET  60636\n",
    "  17     49264     51846     5%                       7216 SOUTH WINCHESTER AVENUE  60636\n",
    "  18     55043     52992    -4%                          3286 WEST COLUMBUS AVENUE  60652\n",
    "  19     54546     51525    -6%                        9999 SOUTH FRANCISCO AVENUE  60805\n",
    "  20     51854     52372     1%                     DAN RYAN EXPRESSWAY PARK MANOR  60621\n",
    "  21     51751     51632     0%                     8852-8854 SOUTH EMERALD AVENUE  60620\n",
    "  22     59734     53515   -10%                              4233 WEST 36TH STREET  60632\n",
    "  23     63691     53728   -16%  CHICAGO MIDWAY INTERNATIONAL AIRPORT WEST 62ND...  60629\n",
    "  24     50879     54909     8%                       1635 SOUTH CHRISTIANA AVENUE  60623\n",
    "  25     55954     54539    -3%                      1632-1746 SOUTH MILLER STREET  60608\n",
    "  26     56841     53516    -6%             LITTLE CUBS FIELD COMFORT STATION 1400  60622\n",
    "  27     61287     52939   -14%                      2151-2153 WEST CHICAGO AVENUE  60651\n",
    "  28     49423     55199    12%                        RML SPECIALTY HOSPITAL 3435  60624\n",
    "  29     61949     55267   -11%                        1241 NORTH RIDGELAND AVENUE  60302\n",
    "  30     72698     55560   -24%                          5118 WEST FLETCHER STREET  60641\n",
    "  31     65045     53724   -17%                          2854 NORTH KEATING AVENUE  60641\n",
    "  32     57204     55184    -4%                        2901 NORTH WASHTENAW AVENUE  60618\n",
    "  33     63695     55598   -13%                    4041-4043 NORTH RICHMOND STREET  60625\n",
    "  34     49922     51599     3%                    11544-11546 SOUTH PEORIA STREET  60827\n",
    "  35     57588     55281    -4%                           3634 WEST BELMONT AVENUE  60618\n",
    "  36     63376     54766   -14%                       2918 NORTH RUTHERFORD AVENUE  60634\n",
    "  37     56120     51538    -8%                         4738-4748 WEST RICE STREET  60651\n",
    "  38     66011     56001   -15%                    7307-7331 WEST IRVING PARK ROAD  60706\n",
    "  39     64291     55882   -13%                  QUEEN OF ALL SAINTS BASILICA 6280  60646\n",
    "  40     58652     55319    -6%                         5536 NORTH ARTESIAN AVENUE  60645\n",
    "  41     56127     55991     0%                          1652 SOUTH CLIFTON AVENUE  60068\n",
    "  42     68102     55870   -18%                          410-420 WEST GRAND AVENUE  60654\n",
    "  43     57668     56170    -3%                              LINCOLN PARK ZOO 2001  60614\n",
    "  44     58758     56058    -5%                         507-513 WEST ALDINE AVENUE  60657\n",
    "  45     60653     55967    -8%       CONGREGATIONAL CHURCH OF JEFFERSON PARK 5320  60630\n",
    "  46     56587     53784    -5%                 UPTOWN BROADWAY BUILDING 4743-4763  60640\n",
    "  47     52108     55074     6%                           2153 WEST BERTEAU AVENUE  60618\n",
    "  48     56246     55014    -2%                         1025 WEST HOLLYWOOD AVENUE  60660\n",
    "  49     59435     54633    -8%                             1426 WEST ESTES AVENUE  60645\n",
    "  50     62383     55809   -11%                       2638 WEST NORTH SHORE AVENUE  60645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd722ad4-781b-4116-a115-71b585e14d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the wards_altered table to view the change \n",
    "print(wards_altered[['ward']].head())\n",
    "\n",
    "# Merge the wards_altered and census tables on the ward column\n",
    "wards_altered_census = wards_altered.merge(census, on='ward')\n",
    "\n",
    "# Print the shape of wards_altered_census\n",
    "print('wards_altered_census table shape:', wards_altered_census.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the first few rows of the census_altered table to view the change \n",
    "print(census_altered[['ward']].head())\n",
    "\n",
    "# Merge the wards and census_altered tables on the ward column\n",
    "wards_census_altered = wards.merge(census_altered, on='ward')\n",
    "\n",
    "# Print the shape of wards_census_altered\n",
    "print('wards_census_altered table shape:', wards_census_altered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a3519-5681-40cd-b8a4-3fb108d593db",
   "metadata": {},
   "source": [
    "## One-to-many relationships\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**In the last lesson, we learned how to merge two DFs together with .merge() method.  In this lesson, we'll discuss different types of relationships between tables.  In particular, we'll discuss the one-to-many relationship.  But first, lets quickly consider what a one-to-one relationshipis.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "In a one-to-one relationship, every row in the left table is related to one and only one row in the right table.  Recall the relationship between the wards table and census table we learned earlier.  \n",
    "\n",
    "And what is a one-to-many relationship?  In a one-to-many relationship, every row in the left table is related to one or more rows in the right table.  \n",
    "\n",
    "Within each ward, there are many businesses.  Image we will merge the wards table with a table of licensed businesses in each ward.  The business license data is stored at another table called licenses.  It holds info such as the business address and ward the business is located in.  The two DFs are related to each other by their ward column.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "When we merge the two tables together with the .merge() method, setting the on= attribute to the column 'ward', the resulting table has both local ward data and business license data.  Notice that ward 1 and its alderman Joe is repeated in the resulting table because the licenses table has many businesses in the 1st ward.  The Pandas takes care of the one-to-many relationship for us and doesnt require anything on our end.  We can use the same syntax as we did with one-to-one relationship.  By printing the shape, we can see our original tablehas 50 rows, while after merging with the licenses table, the resulting table has 1000 rows.  When you merge tables that have a one-to-many relationship, the number of rows returned will likely be different than the number in the left table.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a583af59-7f78-4336-819c-6ef294583b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  account ward  aid                   business               address    zip\n",
      "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
      "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
      "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
      "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
      "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n",
      "  ward            alderman                          address    zip\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n",
      "  ward            alderman               address_ward zip_ward account  aid  \\\n",
      "0    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE    60647   12024  NaN   \n",
      "1    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE    60647   14446  743   \n",
      "2    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE    60647   14624  775   \n",
      "3    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE    60647   14987  NaN   \n",
      "4    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE    60647   15642  814   \n",
      "\n",
      "               business              address_lic zip_lic  \n",
      "0   DIGILOG ELECTRONICS       1038 N ASHLAND AVE   60622  \n",
      "1      EMPTY BOTTLE INC   1035 N WESTERN AVE 1ST   60622  \n",
      "2  LITTLE MEL'S HOT DOG    2205 N CALIFORNIA AVE   60647  \n",
      "3    MR. BROWN'S LOUNGE   2301 W CHICAGO AVE 1ST   60622  \n",
      "4          Beat Kitchen  2000-2100 W DIVISION ST   60622  \n"
     ]
    }
   ],
   "source": [
    "licenses = pd.read_pickle('licenses.p')\n",
    "\n",
    "print(licenses.head())\n",
    "print(ward.head())\n",
    "\n",
    "\n",
    "\n",
    "ward_license = ward.merge(licenses, on='ward', suffixes=('_ward', '_lic'))\n",
    "print(ward_license.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cf916-41b2-466d-8b73-d03ddbe3493e",
   "metadata": {},
   "source": [
    "## One-to-many classification\n",
    "\n",
    "Understanding the difference between a one-to-one and one-to-many relationship is a useful skill. In this exercise, consider a set of tables from an e-commerce website. The hypothetical tables are the following:\n",
    "\n",
    "    A customer table with information about each customer\n",
    "    A cust_tax_info table with customers unique tax IDs\n",
    "    An orders table with information about each order\n",
    "    A products table with details about each unique product sold\n",
    "    An inventory table with information on how much total inventory is available to sell for each product\n",
    "\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "    Select the relationship type that is most appropriate for the relationship between the different tables: One-to-one, or One-to-many.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf875bb-4c74-49f8-b392-dea036e51d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between products and inventory are one-to-one relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707cde94-78f8-4de4-ae0f-339a799d28d4",
   "metadata": {},
   "source": [
    "## One-to-many merge\n",
    "\n",
    "A business may have one or multiple owners. In this exercise, you will continue to gain experience with one-to-many merges by merging a table of business owners, called biz_owners, to the licenses table. Recall from the video lesson, with a one-to-many relationship, a row in the left table may be repeated if it is related to multiple rows in the right table. In this lesson, you will explore this further by finding out what is the most common business owner title. (i.e., secretary, CEO, or vice president)\n",
    "\n",
    "The licenses and biz_owners DataFrames are loaded for you.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Starting with the licenses table on the left, merge it to the biz_owners table on the column account, and save the results to a variable named licenses_owners.\n",
    "#    Group licenses_owners by title and count the number of accounts for each title. Save the result as counted_df\n",
    "    Sort counted_df by the number of accounts in descending order, and save this as a variable named sorted_df.\n",
    "    Use the .head() method to print the first few rows of the sorted_df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8218a72d-e2f0-4958-80e0-bd9bbe1907d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  account ward  aid              business              address    zip  \\\n",
      "0  307071    3  743  REGGIE'S BAR & GRILL      2105 S STATE ST  60616   \n",
      "1      10   10  829            HONEYBEERS  13200 S HOUSTON AVE  60633   \n",
      "2      10   10  829            HONEYBEERS  13200 S HOUSTON AVE  60633   \n",
      "3   10002   14  775           CELINA DELI    5089 S ARCHER AVE  60632   \n",
      "4   10002   14  775           CELINA DELI    5089 S ARCHER AVE  60632   \n",
      "\n",
      "  first_name last_name      title  \n",
      "0     ROBERT     GLICK     MEMBER  \n",
      "1      PEARL   SHERMAN  PRESIDENT  \n",
      "2      PEARL   SHERMAN  SECRETARY  \n",
      "3     WALTER    MROZEK    PARTNER  \n",
      "4     CELINA    BYRDAK    PARTNER  \n",
      "(19497, 9)\n",
      "title            account\n",
      "ASST. SECRETARY  16301      3\n",
      "                 57770      3\n",
      "                 11071      2\n",
      "                 16964      2\n",
      "                 1949       2\n",
      "                           ..\n",
      "VICE PRESIDENT   85943      1\n",
      "                 85956      1\n",
      "                 86083      1\n",
      "                 86202      1\n",
      "                 86216      1\n",
      "Name: account, Length: 17934, dtype: int64\n",
      "title               title             \n",
      "ASST. SECRETARY     ASST. SECRETARY        111\n",
      "BENEFICIARY         BENEFICIARY              4\n",
      "CEO                 CEO                    110\n",
      "DIRECTOR            DIRECTOR               146\n",
      "EXECUTIVE DIRECTOR  EXECUTIVE DIRECTOR      10\n",
      "GENERAL PARTNER     GENERAL PARTNER         21\n",
      "INDIVIDUAL          INDIVIDUAL             268\n",
      "LIMITED PARTNER     LIMITED PARTNER         26\n",
      "MANAGER             MANAGER                134\n",
      "MANAGING MEMBER     MANAGING MEMBER        878\n",
      "MEMBER              MEMBER                 884\n",
      "NOT APPLICABLE      NOT APPLICABLE          11\n",
      "OTHER               OTHER                 1200\n",
      "PARTNER             PARTNER                451\n",
      "PRESIDENT           PRESIDENT             6259\n",
      "PRINCIPAL OFFICER   PRINCIPAL OFFICER       63\n",
      "SECRETARY           SECRETARY             5205\n",
      "SHAREHOLDER         SHAREHOLDER            590\n",
      "SOLE PROPRIETOR     SOLE PROPRIETOR       1658\n",
      "SPOUSE              SPOUSE                  34\n",
      "TREASURER           TREASURER              447\n",
      "TRUSTEE             TRUSTEE                  6\n",
      "VICE PRESIDENT      VICE PRESIDENT         970\n",
      "Name: title, dtype: int64\n",
      "                    account\n",
      "title                      \n",
      "PRESIDENT              6259\n",
      "SECRETARY              5205\n",
      "SOLE PROPRIETOR        1658\n",
      "OTHER                  1200\n",
      "VICE PRESIDENT          970\n",
      "MEMBER                  884\n",
      "MANAGING MEMBER         878\n",
      "SHAREHOLDER             590\n",
      "PARTNER                 451\n",
      "TREASURER               447\n",
      "INDIVIDUAL              268\n",
      "DIRECTOR                146\n",
      "MANAGER                 134\n",
      "ASST. SECRETARY         111\n",
      "CEO                     110\n",
      "PRINCIPAL OFFICER        63\n",
      "SPOUSE                   34\n",
      "LIMITED PARTNER          26\n",
      "GENERAL PARTNER          21\n",
      "NOT APPLICABLE           11\n",
      "EXECUTIVE DIRECTOR       10\n",
      "TRUSTEE                   6\n",
      "BENEFICIARY               4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "biz_owners = pd.read_pickle('business_owners.p')\n",
    "\n",
    "\n",
    "licenses_owners = licenses.merge(biz_owners, on='account')\n",
    "print(licenses_owners.head())\n",
    "print(licenses_owners.shape)\n",
    "\n",
    "\n",
    "\n",
    "# ***************************************************************************************************************** #\n",
    "print(licenses_owners.groupby('title')['account'].value_counts())\n",
    "# ***************************************************************************************************************** #\n",
    "print(licenses_owners.groupby('title')['title'].value_counts())\n",
    "\n",
    "\n",
    "# ***************************************************************************************************************** #\n",
    "counted_df = licenses_owners.groupby('title')['account'].count()\n",
    "# ***************************************************************************************************************** #\n",
    "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
    "\n",
    "\n",
    "counted_df = counted_df.sort_values('account', ascending=False)\n",
    "\n",
    "\n",
    "print(counted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f8d89-444b-48c3-acfb-18c951d990ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the licenses and biz_owners table on account\n",
    "licenses_owners = licenses.merge(biz_owners, on='account')\n",
    "\n",
    "# Group the results by title then count the number of accounts\n",
    "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
    "\n",
    "# Sort the counted_df in desending order\n",
    "sorted_df = counted_df.sort_values('account', ascending=False)\n",
    "\n",
    "# Use .head() method to print the first few rows of sorted_df\n",
    "print(sorted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39832022-8642-4891-af20-5efd45bb826f",
   "metadata": {},
   "source": [
    "## Merging multiple DataFrames\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**In our last lesson, we learned how to merge two tables with a one-to-many relationship using the .merge() method.  Merging data like this is a necessary skill to bring together data from different sources to answer some more complex data questions.  Sometimes we need to merge together more than just two tables to complete our analysis.  \n",
    "\n",
    "\n",
    "In the previous lesson, we used two tables form the city of Chicago.  One table contained business licenses issued by the city, the other table listed info about the local neighborhoods called wards, including the local goverment official's office.  Now we also have a table of businesses that have received small business grant money from Chicago.  \n",
    "# *******************************************************************************************************************\n",
    "# The grants are funded by taxpayers money.  Therefore, it would be helpful to analyze how much grant money each business received and in what ward that business is located.  We then could determine if one ward's business received a disproportionately large anount of grant money.  \n",
    "\n",
    "\n",
    "\n",
    "To pull all of this information togerther, lets first connect our grants table to our licenses table.  The two tables are related by their company name and location.  Lets pause here for a moment.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "If we merge the two tables only using the zip column, then the 60616 zip of Reggie's Bar from the licenses table will be matched to multiple business in the grants table with the same zip.  \n",
    "\n",
    "Our code sample prints the first few rows and some columns of the merged table.  The output of the merge duplicates Reggie's Bar for each matching zip in the grats table, which is not what we want.  If instead, we merge on address only, there is a small risk that the address would repeat in different parts of the city.  Therefore, the best option is to merge the tables using the combination of both address and zip code.  (???????????????)\n",
    "\n",
    "We merge the two DFs as shown before, except in this case, we pass a list of the column names we want to merge on the the on= argument.  This allows us to use multiple columns in the merge.  As before, the matching rows between the two DFs are returned with the columns from the grants table table listed first.  However, when we merge on two columns, in this case address and zip code, we are requiring that both the address and zip code of a row in the left table match the address and zip code of a row in the right table in order for them tobe linked to each other in the merge.  \n",
    "\n",
    "We can now extend this example to third table.  First, we merge the grands table with the wards table on the ward column again, adding suffixes= to the repeated column names.  Note that we're using Python's backslash line continuation method to add the second merge on the next line.  Python will read this as just one line of code.  Don't forget your backslash.  \n",
    "\n",
    "Now our output table has information about grants, business, and wards.  We can now complete our analysis.  We can now sum the grants by ward and plot the results.  Some wards have received more grants than others.  \n",
    "\n",
    "\n",
    "We could continue to merge dditional tables as needed.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(licenses.head())\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "  account ward  aid                   business               address    zip\n",
    "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
    "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
    "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
    "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
    "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n",
    "\n",
    "\n",
    "\n",
    "grants = pd.read_csv('Small_Business_Grant_Agreements.csv')\n",
    "\n",
    "print(grants.head())\n",
    "\n",
    "-----------------------------------------------------------\n",
    "    address          | zip   | grant     | company\n",
    "0   1000 S Kostn...  | 60624 | 148914.50 | Nationwide F...\n",
    "1   1000 W 35th ST   | 60609 | 100000.00 | Small Batch,...\n",
    "2   1000 W Fulto...  | 60612 | 34412.50  | Fulton Marke...\n",
    "3   10008 S West...  | 60643 | 12285.32  | Law Offices...\n",
    "4   1002 W Argyl...  | 60640 | 28998.75  | Masala's Ind...\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "grants_licenses = grants.merge(licenses, on='zip')\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "print(grants_licenses.loc[grants_licenses['business']=='Reggie's Bar & Grill', \n",
    "                         ['grant', 'company', 'account', 'ward', 'business']])\n",
    "# *******************************************************************************************************************\n",
    "\n",
    "-----------------------------------------------------------------------------\n",
    "    grant     | company         | account   | ward  | business\n",
    "0   136443.07 | Cedars Medit... | 307071    | 3     | Reggie's Bar & Grill\n",
    "1   39943.15  | Darryl & Fyl... | 307071    | 3     | Reggie's Bar & Grill\n",
    "2   31250.0   | Jgf Management  | 307071    | 3     | Reggie's Bar & Grill\n",
    "3   143427.79 | Hyde Park An... | 307071    | 3     | Reggie's Bar & Grill\n",
    "4   69500.00  | Zberry Inc      | 307071    | 3     | Reggie's Bar & Grill\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "grants.merge(licenses, on=['address', 'zip'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "grants_licenses_ward = grants.merge(licenses, on=['zip', 'address']) \\ \n",
    "                                    .merge(wards, on='ward', suffixes=('_bus', '_ward'))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grants_licenses_ward.groupby('ward')['grand'].agg('sum').plot(kind='bar', y='grant')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f03ce525-e278-451a-9d38-3f0bbc71a5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  account ward  aid                   business               address    zip\n",
      "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
      "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
      "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
      "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
      "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n"
     ]
    }
   ],
   "source": [
    "print(licenses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c113c-0ece-4cdd-91b2-3910e46d9d06",
   "metadata": {},
   "source": [
    "## Total riders in a month\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Your goal is to find the total number of rides provided to passengers passing through the Wilson station (station_name == 'Wilson') when riding Chicago's public transportation system on weekdays (day_type == 'Weekday') in July (month == 7). Luckily, Chicago provides this detailed data, but it is in three different tables. You will work on merging these tables together to answer the question. This data is different from the business related data you have seen so far, but all the information you need to answer the question is provided.\n",
    "\n",
    "The cal, ridership, and stations DataFrames have been loaded for you. The relationship between the tables can be seen in the diagram below.\n",
    "\n",
    "cal           ridership        stations\n",
    "  year -        station_id ----- station_id\n",
    "  month --    - year             station_name\n",
    "  day ---    -- month            location\n",
    "  day_type  --- day\n",
    "                rides\n",
    "\n",
    "Table diagram. The cal table relates to ridership via year, month, and day. The ridership table relates to the stations table via station_id.\n",
    "Instructions 1/3\n",
    "50 XP\n",
    "\n",
    "    Question 1\n",
    "    Merge the ridership and cal tables together, starting with the ridership table on the left and save the result to the variable ridership_cal. If you code takes too long to run, your merge conditions might be incorrect.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    Extend the previous merge to three tables by also merging the stations table.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 3\n",
    "    Create a variable called filter_criteria to select the appropriate rows from the merged table so that you can sum the rides column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de2385e6-f5d2-4217-bddc-206fd98dd95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_id        station_name                 location\n",
      "0      40010  Austin-Forest Park  (41.870851, -87.776812)\n",
      "1      40020         Harlem-Lake  (41.886848, -87.803176)\n",
      "2      40030        Pulaski-Lake  (41.885412, -87.725404)\n",
      "3      40040        Quincy/Wells   (41.878723, -87.63374)\n",
      "4      40050               Davis   (42.04771, -87.683543)\n",
      "   year  month  day        day_type\n",
      "0  2019      1    1  Sunday/Holiday\n",
      "1  2019      1    2         Weekday\n",
      "2  2019      1    3         Weekday\n",
      "3  2019      1    4         Weekday\n",
      "4  2019      1    5        Saturday\n",
      "  station_id  year  month  day  rides\n",
      "0      40010  2019      1    1    576\n",
      "1      40010  2019      1    2   1457\n",
      "2      40010  2019      1    3   1543\n",
      "3      40010  2019      1    4   1621\n",
      "4      40010  2019      1    5    719\n",
      "     station_id  year  month  day  rides  day_type\n",
      "654       41500  2019      3   14   2722   Weekday\n",
      "2087      41660  2019      8   20  21143   Weekday\n",
      "2830      40540  2019     11   11   5925   Weekday\n",
      "2154      40120  2019      8   28   3329   Weekday\n",
      "2370      40120  2019      9   21   1562  Saturday\n",
      "69        41500  2019      1    8   2600   Weekday\n",
      "2312      41660  2019      9   14  14822  Saturday\n",
      "     station_id  year  month  day  rides        day_type    station_name  \\\n",
      "1488      40540  2019      1   29   5930         Weekday          Wilson   \n",
      "1165      40120  2019      3   12   3196         Weekday     35th/Archer   \n",
      "2973      41660  2019      2   23   9935        Saturday      Lake/State   \n",
      "2081      41260  2019      9   14   1052        Saturday     Austin-Lake   \n",
      "870       40770  2019      4   20   2016        Saturday        Lawrence   \n",
      "2670      41440  2019      5   26    791  Sunday/Holiday   Addison-Brown   \n",
      "2414      41500  2019      8   13   2735         Weekday  Montrose-Brown   \n",
      "504       40080  2019      4   19   4138         Weekday        Sheridan   \n",
      "\n",
      "                     location  \n",
      "1488  (41.964273, -87.657588)  \n",
      "1165  (41.829353, -87.680622)  \n",
      "2973  (41.884809, -87.627813)  \n",
      "2081  (41.887293, -87.774135)  \n",
      "870   (41.969139, -87.658493)  \n",
      "2670  (41.947028, -87.674642)  \n",
      "2414  (41.961756, -87.675047)  \n",
      "504   (41.953775, -87.654929)  \n",
      "\n",
      "\n",
      "140005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "stations = pd.read_pickle('stations.p')\n",
    "cal = pd.read_pickle('cta_calendar.p')\n",
    "ridership = pd.read_pickle('cta_ridership.p')\n",
    "\n",
    "\n",
    "print(stations.head())\n",
    "print(cal.head())\n",
    "print(ridership.head())\n",
    "\n",
    "\n",
    "ridership_cal = ridership.merge(cal, on=['year', 'month', 'day'])\n",
    "print(ridership_cal.sample(7))\n",
    "\n",
    "\n",
    "\n",
    "ridership_cal_stations = ridership_cal.merge(stations, on='station_id')\n",
    "print(ridership_cal_stations.sample(8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filter_criteria = ridership_cal_stations.loc[(ridership_cal_stations['station_name']=='Wilson') & \n",
    "                                         (ridership_cal_stations['month']==7) & \n",
    "                                         (ridership_cal_stations['day_type']=='Weekday'), 'rides'].sum()#value_counts()\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(filter_criteria)\n",
    "\n",
    "\n",
    "\n",
    "# To feel and to think hwo we get there, whats the best approach doing it.  Think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ca0b7-050c-49f3-aa53-ba78ca8fe980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the ridership, cal, and stations tables\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "            \t\t\t\t.merge(stations, on='station_id')\n",
    "\n",
    "\n",
    "\n",
    "# ***************************************************************************************************************** #\n",
    "\n",
    "# Merge the ridership, cal, and stations tables\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "\t\t\t\t\t\t\t.merge(stations, on='station_id')\n",
    "\n",
    "# Create a filter to filter ridership_cal_stations\n",
    "filter_criteria = ((ridership_cal_stations['month'] == ____) \n",
    "                   & (ridership_cal_stations['day_type'] == ____) \n",
    "                   & (ridership_cal_stations['station_name'] == ____))\n",
    "\n",
    "# Use .loc and the filter to select for rides\n",
    "print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())\n",
    "\n",
    "# ***************************************************************************************************************** #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895df3e-968e-4483-b45d-7c0512888d2b",
   "metadata": {},
   "source": [
    "## Three table merge\n",
    "\n",
    "To solidify the concept of a three DataFrame merge, practice another exercise. A reasonable extension of our review of Chicago business data would include looking at demographics information about the neighborhoods where the businesses are. A table with the median income by zip code has been provided to you. You will merge the licenses and wards tables with this new income-by-zip-code table called zip_demo.\n",
    "\n",
    "The licenses, wards, and zip_demo DataFrames have been loaded for you.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "#    Starting with the licenses table, merge to it the zip_demo table on the zip column. Then merge the resulting table to the wards table on the ward column. Save result of the three merged tables to a variable named licenses_zip_ward.\n",
    "    Group the results of the three merged tables by the column alderman and find the median income.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b397c220-8ea8-4b1c-b768-e8d5ec5c57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  account ward  aid                   business               address    zip\n",
      "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
      "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
      "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
      "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
      "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n",
      "  ward            alderman                          address    zip\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n",
      "     zip  income\n",
      "0  60630   70122\n",
      "1  60640   50488\n",
      "2  60622   87143\n",
      "3  60614  100116\n",
      "4  60608   41226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alderman\n",
       "Ameya Pawar                   66246.0\n",
       "Anthony A. Beale              38206.0\n",
       "Anthony V. Napolitano         82226.0\n",
       "Ariel E. Reyboras             33959.0\n",
       "Brendan Reilly               104629.0\n",
       "Brian Hopkins                 87143.0\n",
       "Carlos Ramirez-Rosa           68223.0\n",
       "Carrie M. Austin              38206.0\n",
       "Chris Taliaferro              41307.0\n",
       "Daniel \"Danny\" Solis          41226.0\n",
       "David H. Moore                27573.0\n",
       "Deborah Mell                  66246.0\n",
       "Debra L. Silverstein          50554.0\n",
       "Derrick G. Curtis             65770.0\n",
       "Edward M. Burke               42335.0\n",
       "Emma M. Mitts                 36283.0\n",
       "George Cardenas               41226.0\n",
       "Gilbert Villegas              92240.0\n",
       "Gregory I. Mitchell           38417.0\n",
       "Harry Osterman                50488.0\n",
       "Howard B. Brookins, Jr.       33304.0\n",
       "James Cappleman               50488.0\n",
       "Jason C. Ervin                38756.0\n",
       "Joe Moore                     39163.0\n",
       "John S. Arena                 70122.0\n",
       "Leslie A. Hairston            24941.0\n",
       "Margaret Laurino              70122.0\n",
       "Marty Quinn                   41856.0\n",
       "Matthew J. O'Shea             59488.0\n",
       "Michael R. Zalewski           67045.0\n",
       "Michael Scott, Jr.            22467.0\n",
       "Michelle A. Harris            32558.0\n",
       "Michelle Smith               100116.0\n",
       "Milagros \"Milly\" Santiago     41307.0\n",
       "Nicholas Sposato              62223.0\n",
       "Pat Dowell                    33959.0\n",
       "Patrick Daley Thompson        33959.0\n",
       "Patrick J. O'Connor           50554.0\n",
       "Proco \"Joe\" Moreno            68223.0\n",
       "Raymond A. Lopez              27573.0\n",
       "Ricardo Munoz                 31445.0\n",
       "Roberto Maldonado             87143.0\n",
       "Roderick T. Sawyer            32558.0\n",
       "Scott Waguespack             100116.0\n",
       "Susan Sadlowski Garza         38417.0\n",
       "Tom Tunney                    88708.0\n",
       "Toni L. Foulkes               41856.0\n",
       "Walter Burnett, Jr.           38756.0\n",
       "William D. Burns              46340.0\n",
       "Willie B. Cochran             28024.0\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses = pd.read_pickle('licenses.p')\n",
    "wards = pd.read_pickle('ward.p')\n",
    "zip_demo = pd.read_pickle('zip_demo.p')\n",
    "\n",
    "\n",
    "print(licenses.head())\n",
    "print(wards.head())\n",
    "print(zip_demo.head())\n",
    "\n",
    "\n",
    "licenses_zip_ward = licenses.merge(zip_demo, on='zip').merge(wards, on='zip')\n",
    "licenses_zip_ward.groupby('alderman')['income'].median()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac7a58-3d52-4c57-a012-c4e2cddb43df",
   "metadata": {},
   "source": [
    "## One-to-many merge with multiple tables\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# In this exercise, assume that you are looking to start a business in the city of Chicago. Your perfect idea is to start a company that uses goats to mow the lawn for other businesses. However, you have to choose a location in the city to put your goat farm. You need a location with a great deal of space and relatively few businesses and people around to avoid complaints about the smell. You will need to merge three tables to help you choose your location. The land_use table has info on the percentage of vacant land by city ward. The census table has population by ward, and the licenses table lists businesses by ward.\n",
    "\n",
    "The land_use, census, and licenses tables have been loaded for you.\n",
    "Instructions 1/3\n",
    "35 XP\n",
    "\n",
    "    Question 1\n",
    "    Merge land_use and census on the ward column. Merge the result of this with licenses on the ward column, using the suffix _cen for the left table and _lic for the right table. Save this to the variable land_cen_lic.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "#    Group land_cen_lic by ward, pop_2010 (the population in 2010), and vacant, then count the number of accounts. Save the results to pop_vac_lic.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 3\n",
    "    Sort pop_vac_lic by vacant, account, andpop_2010 in descending, ascending, and ascending order respectively. Save it as sorted_pop_vac_lic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "763972ed-0885-4d2e-928f-de6177493700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ward  residential  commercial  industrial  vacant  other  pop_2000  \\\n",
      "0    1           41           9           2       2     46     52951   \n",
      "1    1           41           9           2       2     46     52951   \n",
      "2    1           41           9           2       2     46     52951   \n",
      "3    1           41           9           2       2     46     52951   \n",
      "4    1           41           9           2       2     46     52951   \n",
      "\n",
      "   pop_2010 change                  address_cen zip_cen account  aid  \\\n",
      "0     56149     6%  2765 WEST SAINT MARY STREET   60647   12024  NaN   \n",
      "1     56149     6%  2765 WEST SAINT MARY STREET   60647   14446  743   \n",
      "2     56149     6%  2765 WEST SAINT MARY STREET   60647   14624  775   \n",
      "3     56149     6%  2765 WEST SAINT MARY STREET   60647   14987  NaN   \n",
      "4     56149     6%  2765 WEST SAINT MARY STREET   60647   15642  814   \n",
      "\n",
      "               business              address_lic zip_lic  \n",
      "0   DIGILOG ELECTRONICS       1038 N ASHLAND AVE   60622  \n",
      "1      EMPTY BOTTLE INC   1035 N WESTERN AVE 1ST   60622  \n",
      "2  LITTLE MEL'S HOT DOG    2205 N CALIFORNIA AVE   60647  \n",
      "3    MR. BROWN'S LOUNGE   2301 W CHICAGO AVE 1ST   60622  \n",
      "4          Beat Kitchen  2000-2100 W DIVISION ST   60622  \n",
      "  ward  pop_2010  vacant  account\n",
      "0    1     56149       2      253\n",
      "1   10     51535      14      130\n",
      "2   11     51497       5      201\n",
      "3   12     52235       4      255\n",
      "4   13     53722       1      101\n",
      "   ward  pop_2010  vacant  account\n",
      "47    7     51581      19       80\n",
      "12   20     52372      15      123\n",
      "1    10     51535      14      130\n",
      "16   24     54909      13       98\n",
      "7    16     51954      13      156\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "land_use = pd.read_pickle('land_use.p')\n",
    "census = pd.read_pickle('census.p')\n",
    "licenses = pd.read_pickle('licenses.p')\n",
    "\n",
    "\n",
    "\n",
    "# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, on='ward').merge(licenses, on='ward', suffixes=('_cen', '_lic'))\n",
    "print(land_cen_lic.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, on='ward') \\\n",
    "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
    "\n",
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward', 'pop_2010', 'vacant'], \n",
    "                                   as_index=False).agg({'account':'count'}).sort_index(level=['ward', 'pop_2010', 'vacant'])\n",
    "print(pop_vac_lic.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, on='ward') \\\n",
    "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
    "\n",
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'], \n",
    "                                   as_index=False).agg({'account':'count'})\n",
    "\n",
    "# Sort pop_vac_lic and print the results\n",
    "sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant', 'account', 'pop_2010'], \n",
    "                                             ascending=[False, True, True])\n",
    "\n",
    "# Print the top few rows of sorted_pop_vac_lic\n",
    "print(sorted_pop_vac_lic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee8e30-ee36-4d53-9b91-afd825f38a63",
   "metadata": {},
   "source": [
    "# Sort index we have to specify level=[columns], not needed when we apply it to the sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d91838-6d40-405c-b1a4-378854ec2964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1705e43c-2d8c-4a57-9bad-02d1234e0be3",
   "metadata": {},
   "source": [
    "## Left join\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**In this lesson, we'll discuss how a left join works, which is another way to merge two tables.  Before we start about left joins, lets quickly review what we have learned so far.  \n",
    "\n",
    "In chapter 1, we introduced the Pandas df.merge() method that allows us to combine two tables by specifying one or more key columns to link  the tables by.  By default, the .merge() method performs an inner join, returning only the rows of data with matching values in the key columns of both tables.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "In this lesson, we'll talk about the idea of a left join.  A left join returns all rows of data from the left table and only those rows from the right table where key columns match.  \n",
    "\n",
    "\n",
    "To help us learn more about left joins and other concepts in this chapter, we'll use data from The Movie Database, a company-built movie database  with info on thousands of movies, their casts, and popularity.  In our next example, we have two tables from The Movie Database that we want to merge.  \n",
    "\n",
    "Our first table, named movies, holds info about individual movies such as the title name and its popularity.  Additionally, each movie is given an ID number.  Our second table is named taglines, which contains a movie ID number and the tag line for the movie.  To merge these tables with a left join, we use our merge method similar to what we learned in chapter 1.  Here we list the movie table first and merge  it to the taglines table on the on='id' column in both tables.  However, notice an additional argument named how=, this argument defines how to merge the two tables.  Remember that Pandas use NaN to denote missing data.  \n",
    "\n",
    "After the merge, our resulting table has a 4805 rows.  This is because we are returning all of the rows of data from the movies table, and the relationship between the movies table and taglines table is one-to-one.  Therefore, in a one-to-one merge like this, a left join will always return the same number rows as the left table.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "left table                     right table                      result table\n",
    "\n",
    "------------------------      -------------------              ----------------------------------\n",
    " A      | B      | C          C       | D                       A      | B     | C     | D\n",
    " A2     | B2     | C2         C1      | D1                      A2     | B2    | C2    | D1\n",
    " A3     | B3     | C3         C2      | D2                      A3     | B3    | C3    |\n",
    " A4     | B4     | C4         C4      | D4                      A4     | B4    | C4    | D4\n",
    "                              C5      | D5\n",
    "\n",
    "\n",
    "movies = pd.read_csv('tmdb_movies.csv')\n",
    "print(movies.head())\n",
    "print(movies.shape)\n",
    "\n",
    "------------------------------------------------------------\n",
    "      id                 title  popularity release_date\n",
    "0    257          Oliver Twist   20.415572   2005-09-23\n",
    "1  14290  Better Luck Tomorrow    3.877036   2002-01-12\n",
    "2  38365             Grown Ups   38.864027   2010-06-24\n",
    "3   9672              Infamous    3.680896   2006-11-16\n",
    "4  12819       Alpha and Omega   12.300789   2010-09-17\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161a716a-11d7-48b1-b04a-0d0a44d48aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                 title  popularity release_date\n",
      "0    257          Oliver Twist   20.415572   2005-09-23\n",
      "1  14290  Better Luck Tomorrow    3.877036   2002-01-12\n",
      "2  38365             Grown Ups   38.864027   2010-06-24\n",
      "3   9672              Infamous    3.680896   2006-11-16\n",
      "4  12819       Alpha and Omega   12.300789   2010-09-17\n",
      "(4803, 4)\n",
      "       id                                         tagline\n",
      "0   19995                     Enter the World of Pandora.\n",
      "1     285  At the end of the world, the adventure begins.\n",
      "2  206647                           A Plan No One Escapes\n",
      "3   49026                                 The Legend Ends\n",
      "4   49529            Lost in our world, found in another.\n",
      "(3955, 2)\n",
      "\n",
      "\n",
      "      id                 title  popularity release_date  \\\n",
      "0    257          Oliver Twist   20.415572   2005-09-23   \n",
      "1  14290  Better Luck Tomorrow    3.877036   2002-01-12   \n",
      "2  38365             Grown Ups   38.864027   2010-06-24   \n",
      "3   9672              Infamous    3.680896   2006-11-16   \n",
      "4  12819       Alpha and Omega   12.300789   2010-09-17   \n",
      "\n",
      "                                           tagline  \n",
      "0                                              NaN  \n",
      "1             Never underestimate an overachiever.  \n",
      "2  Boys will be boys. . . some longer than others.  \n",
      "3          There's more to the story than you know  \n",
      "4                           A Pawsome 3D Adventure  \n",
      "(4803, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_pickle('movies.p')\n",
    "print(movies.head())\n",
    "print(movies.shape)\n",
    "\n",
    "\n",
    "taglines = pd.read_pickle('taglines.p')\n",
    "print(taglines.head())\n",
    "print(taglines.shape)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "movies_taglines = movies.merge(taglines, on='id', how='left')\n",
    "print(movies_taglines.head())\n",
    "print(movies_taglines.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e5e95-d3cb-4ddb-a9cd-32e94f4f53ad",
   "metadata": {},
   "source": [
    "## Counting missing rows with left join\n",
    "\n",
    "The Movie Database is supported by volunteers going out into the world, collecting data, and entering it into the database. This includes financial data, such as movie budget and revenue. If you wanted to know which movies are still missing data, you could use a left join to identify them. Practice using a left join by merging the movies table and the financials table.\n",
    "\n",
    "The movies and financials tables have been loaded for you.\n",
    "Instructions 1/3\n",
    "35 XP\n",
    "\n",
    "    Question 1\n",
    "What column is likely the best column to merge the two tables on?\n",
    "Possible Answers\n",
    "\n",
    "    on='budget'\n",
    "    on='popularity'\n",
    "    on='id'\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2     Missing\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 3     Missing\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9d0d35-9764-4fae-9fc0-fc22cfaa77aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id     budget       revenue\n",
      "0   19995  237000000  2.787965e+09\n",
      "1     285  300000000  9.610000e+08\n",
      "2  206647  245000000  8.806746e+08\n",
      "3   49026  250000000  1.084939e+09\n",
      "4   49529  260000000  2.841391e+08\n",
      "(3229, 3)\n",
      "      id                 title  popularity release_date\n",
      "0    257          Oliver Twist   20.415572   2005-09-23\n",
      "1  14290  Better Luck Tomorrow    3.877036   2002-01-12\n",
      "2  38365             Grown Ups   38.864027   2010-06-24\n",
      "3   9672              Infamous    3.680896   2006-11-16\n",
      "4  12819       Alpha and Omega   12.300789   2010-09-17\n",
      "(4803, 4)\n",
      "      id                 title  popularity release_date      budget  \\\n",
      "0    257          Oliver Twist   20.415572   2005-09-23  50000000.0   \n",
      "1  14290  Better Luck Tomorrow    3.877036   2002-01-12         NaN   \n",
      "2  38365             Grown Ups   38.864027   2010-06-24  80000000.0   \n",
      "3   9672              Infamous    3.680896   2006-11-16  13000000.0   \n",
      "4  12819       Alpha and Omega   12.300789   2010-09-17  20000000.0   \n",
      "\n",
      "       revenue  \n",
      "0   42093706.0  \n",
      "1          NaN  \n",
      "2  271430189.0  \n",
      "3    1151330.0  \n",
      "4   39300000.0  \n",
      "(4803, 6)\n",
      "\n",
      "\n",
      "id                 0\n",
      "title              0\n",
      "popularity         0\n",
      "release_date       1\n",
      "budget          1574\n",
      "revenue         1574\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "financials = pd.read_pickle('financials.p')\n",
    "print(financials.head())\n",
    "print(financials.shape)\n",
    "\n",
    "\n",
    "print(movies.head())\n",
    "print(movies.shape)\n",
    "\n",
    "\n",
    "movies_financials = movies.merge(financials, on='id', how='left')\n",
    "print(movies_financials.head())\n",
    "print(movies_financials.shape)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(movies_financials.isna().sum())\n",
    "\n",
    "\n",
    "# If you wanted to know which movies are still missing data, you could use a left join to identify them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f7b80-e0a0-4d8b-8cb4-b034d1c23f55",
   "metadata": {},
   "source": [
    "## Enriching a dataset\n",
    "\n",
    "Setting how='left' with the .merge()method is a useful technique for enriching or enhancing a dataset with additional information from a different table. In this exercise, you will start off with a sample of movie data from the movie series Toy Story. Your goal is to enrich this data by adding the marketing tag line for each movie. You will compare the results of a left join versus an inner join.\n",
    "\n",
    "The toy_story DataFrame contains the Toy Story movies. The toy_story and taglines DataFrames have been loaded for you.\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "\n",
    "    Question 1\n",
    "    Merge toy_story and taglines on the id column with a left join, and save the result as toystory_tag.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    With toy_story as the left table, merge to it taglines on the id column with an inner join, and save as toystory_tag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e098679-8147-4ab9-aa7c-616fb93650b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3843563265.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_6010/3843563265.py\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    print(toystory_tag.)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(movies.head())\n",
    "\n",
    "print(movies[movies['title']=='Toy Story'].copy())\n",
    "\n",
    "toy_story = movies[movies.filter(like ='Toy Story', axis=1)]\n",
    "print(toy_story)\n",
    "\n",
    "\n",
    "# Merge the toy_story and taglines tables with a left join\n",
    "toystory_tag = toy_story.merge(taglines, on='id', how='left')\n",
    "\n",
    "# Print the rows and shape of toystory_tag\n",
    "print(toystory_tag.)\n",
    "print(toystory_tag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4225b25-5bf4-4abc-a826-28115393ec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd87c3f-279a-492a-9437-d5907d471170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4a8a1-5dfa-4121-b858-e25b046db447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e71797-8097-497c-b929-cc8491ec0e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1da53-455a-45b0-b9c9-bc3ab3a2d3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d6b06-91cc-4798-b6bf-b162cf512356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac1874-e1b7-4892-8418-5ed6c0ea89f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f37bb4-470d-4aed-aa86-a21312e7b083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c130c-ca00-49b4-b828-66148e8e354c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80fa85-aa23-4241-a56b-6723cd23c226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa0a9f-1c1c-44d2-8cb2-ed06ffcd7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db369f-e76e-4b32-8e23-94ea7ed064c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fd943-5d28-4d7f-a989-67a7815d55f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a50d5-01b3-45e2-ba77-79ac6720d2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24108488-8d1c-4296-a891-f497e0c41fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48940f-b990-4b9e-a020-a4569805e8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e7ba2-767f-4bfe-a129-c72d496f0b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176f9f5-11f8-4c12-a0c6-2459f525eaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791293e-4737-4756-8fcd-3a6f36643fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
