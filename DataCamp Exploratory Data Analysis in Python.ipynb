{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15aa4386-f908-41bc-90e6-70a59eac07e0",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee08dd-d6b6-4c0b-8720-714ecf959d36",
   "metadata": {},
   "source": [
    "## Course Description\n",
    "\n",
    "How do we get from data to answers? Exploratory data analysis is a process for exploring datasets, answering questions, and visualizing results. This course presents the tools you need to clean and validate data, to visualize distributions and relationships between variables, and to use regression models to predict and explain. You'll explore data related to demographics and health, including the National Survey of Family Growth and the General Social Survey. But the methods you learn apply to all areas of science, engineering, and business. You'll use Pandas, a powerful library for working with data, and other core Python libraries including NumPy and SciPy, StatsModels for regression, and Matplotlib for visualization. With these tools and skills, you will be prepared to work with real data, make discoveries, and present compelling results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8202088-aec0-4aa0-a0fb-2e7806b56bfc",
   "metadata": {},
   "source": [
    "##  Read, clean, and validate\n",
    "Free\n",
    "0%\n",
    "\n",
    "The first step of almost any data project is to read the data, check for errors and special cases, and prepare data for analysis. This is exactly what you'll do in this chapter, while working with a dataset obtained from the National Survey of Family Growth.\n",
    "\n",
    "    DataFrames and Series    50 xp\n",
    "    Read the codebook    50 xp\n",
    "    Exploring the NSFG data    100 xp\n",
    "    Clean and Validate    50 xp\n",
    "    Validate a variable    50 xp\n",
    "    Clean a variable    100 xp\n",
    "    Compute a variable    100 xp\n",
    "    Filter and visualize    50 xp\n",
    "    Make a histogram    100 xp\n",
    "    Compute birth weight    100 xp\n",
    "    Filter    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ec9d8-7915-432f-966a-bb737c78369d",
   "metadata": {},
   "source": [
    "##  Distributions\n",
    "0%\n",
    "\n",
    "In the first chapter, having cleaned and validated your data, you began exploring it by using histograms to visualize distributions. In this chapter, you'll learn how to represent distributions using Probability Mass Functions (PMFs) and Cumulative Distribution Functions (CDFs). You'll learn when to use each of them, and why, while working with a new dataset obtained from the General Social Survey.\n",
    "\n",
    "    Probability mass functions    50 xp\n",
    "    Make a PMF    100 xp\n",
    "    Plot a PMF    100 xp\n",
    "    Cumulative distribution functions    50 xp\n",
    "    Make a CDF    100 xp\n",
    "    Compute IQR    100 xp\n",
    "    Plot a CDF    100 xp\n",
    "    Comparing distributions    50 xp\n",
    "    Distribution of education    50 xp\n",
    "    Extract education levels    100 xp\n",
    "    Plot income CDFs    100 xp\n",
    "    Modeling distributions    50 xp\n",
    "    Distribution of income    100 xp\n",
    "    Comparing CDFs    100 xp\n",
    "    Comparing PDFs    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde4d2d0-76dc-486d-9081-94748f72670b",
   "metadata": {},
   "source": [
    "##  Relationships\n",
    "0%\n",
    "\n",
    "Up until this point, you've only looked at one variable at a time. In this chapter, you'll explore relationships between variables two at a time, using scatter plots and other visualizations to extract insights from a new dataset obtained from the Behavioral Risk Factor Surveillance Survey (BRFSS). You'll also learn how to quantify those relationships using correlation and simple regression.\n",
    "\n",
    "    Exploring relationships    50 xp\n",
    "    PMF of age    100 xp\n",
    "    Scatter plot    100 xp\n",
    "    Jittering    100 xp\n",
    "    Visualizing relationships    50 xp\n",
    "    Height and weight    100 xp\n",
    "    Distribution of income    100 xp\n",
    "    Income and height    100 xp\n",
    "    Correlation    50 xp\n",
    "    Computing correlations    100 xp\n",
    "    Interpreting correlations    50 xp\n",
    "    Simple regression    50 xp\n",
    "    Income and vegetables    100 xp\n",
    "    Fit a line    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f079e58a-7fb2-4030-a56a-4cc91c5f6ecb",
   "metadata": {},
   "source": [
    "##  Multivariate Thinking\n",
    "0%\n",
    "\n",
    "Explore multivariate relationships using multiple regression to describe non-linear relationships and logistic regression to explain and predict binary variables.\n",
    "\n",
    "    Limits of simple regression    50 xp\n",
    "    Regression and causation    50 xp\n",
    "    Using StatsModels    100 xp\n",
    "    Multiple regression    50 xp\n",
    "    Plot income and education    100 xp\n",
    "    Non-linear model of education    100 xp\n",
    "    Visualizing regression results    50 xp\n",
    "    Making predictions    100 xp\n",
    "    Visualizing predictions    100 xp\n",
    "    Logistic regression    50 xp\n",
    "    Predicting a binary variable    100 xp\n",
    "    Next steps    50 xp \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b236a29-5548-4696-bec1-5142245a3acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "104460e9-b14c-4e06-8b9c-59b56345714c",
   "metadata": {},
   "source": [
    "## DataFrames and Series\n",
    "\n",
    "\n",
    "\n",
    "Welcome to Exploratory Data Analysis in Python.  The instructor's name is Allen Downey.  [The goal of exploratory data analysis is to answer the questions and guide decision making].  As a first example, we'll start with a simple __question: what is the average birth weight of babies in teh United States?__  To answera question like this, we have to find an appropriate dataset or run an experiment to collect it.  Then we have to get the data into our development environment and prepare it for analysis, which involves cleaning and validation.  For this questionwe'll use data from the National Survery of Family Growth, which is available from the National Center for Health Statistics.  The 2012-2015 dataset includes information about a representative sample of women in the USA and their children.  \n",
    "\n",
    "The Python module we'll use to read and analyze data in Pandas.  Pandas can read data in most common formats, including CSV, Excel, and the format NSFG data is in, HDF5 (DO you recall how we test importing data from different sources with Pandas? get remember it ).  The result from \"pd.read_hdf('nsfg.hdf5', 'nsfg')\" is a DataFrame, which is the primary data structure Pandas uses to store data.  Using \"df.head()\" giving us pregnancy for each of women who participated in the survey, and one column for each variable.  The DF has an attribute \".shape\", which is the number of rows and columns.  And the \".columns\" attributes, as an [index] (DF are formed by 3 object, index, columns, data, do you recall when we learned this topic, go back to read it again).  Thats another Pandas data structure, similar to a list; in this case its a list of variables names, which are strings.  For the reliable information about the data, you have to read teh documentation.  Say what does this columns \"birthwgt_lb1\" means?  The documentation tell us that it is the weight in pounds of teh first baby from this pregnancy, for cases of live birth.  \n",
    "\n",
    "In many ways, a DF is like a Python's dictionary, where the variable names are the keys and the columns are the values.  You can select a column from a DF using the bracket operator, with a string as the key.  The result is a Series, which is another Pandas data structure.  In this case the Series contains the birth weights, in pounds, of the live births (or in the case of multiple births, the first baby).  The \"df.head()\" shows the first 5 rows of the Seris and the name of the Series, and the datatype; float64 means that these values are 64-bit floating point numbers.  Notice that one of the values is NaN, which stands for \"Not a Number\".  NaN is a special value that can indicate invalid or missing data.  In that example, the pregnancy did not end in live birth, so birth weight is inapplicable.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c527de8-d8f9-449e-8629-f605e965cb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "   caseid  outcome  birthwgt_lb1  birthwgt_oz1  prglngth  nbrnaliv  agecon  \\\n",
      "0   60418        1           5.0           4.0        40       1.0    2000   \n",
      "1   60418        1           4.0          12.0        36       1.0    2291   \n",
      "2   60418        1           5.0           4.0        36       1.0    3241   \n",
      "3   60419        6           NaN           NaN        33       NaN    3650   \n",
      "4   60420        1           8.0          13.0        41       1.0    2191   \n",
      "\n",
      "   agepreg  hpagelb  wgt2013_2015  \n",
      "0   2075.0     22.0   3554.964843  \n",
      "1   2358.0     25.0   3554.964843  \n",
      "2   3308.0     52.0   3554.964843  \n",
      "3      NaN      NaN   2484.535358  \n",
      "4   2266.0     24.0   2903.782914   \n",
      "\n",
      "(9358, 10) \n",
      "\n",
      "Index(['caseid', 'outcome', 'birthwgt_lb1', 'birthwgt_oz1', 'prglngth',\n",
      "       'nbrnaliv', 'agecon', 'agepreg', 'hpagelb', 'wgt2013_2015'],\n",
      "      dtype='object') \n",
      "\n",
      "Case Id: \n",
      " 0       60418\n",
      "1       60418\n",
      "2       60418\n",
      "3       60419\n",
      "4       60420\n",
      "        ...  \n",
      "9353    70615\n",
      "9354    70616\n",
      "9355    70616\n",
      "9356    70619\n",
      "9357    70619\n",
      "Name: caseid, Length: 9358, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_hdf('nsfg.hdf5', 'nsfg')\n",
    "print(type(df), '\\n')\n",
    "\n",
    "\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "print(df.shape, '\\n')\n",
    "print(df.columns, '\\n')\n",
    "\n",
    "\n",
    "print(\"Case Id: \\n\", df['caseid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39279dfc-235f-4efa-8583-57f963d9744f",
   "metadata": {},
   "source": [
    "## Read the codebook\n",
    "\n",
    "When you work with datasets like the NSFG, it is important to read the documentation carefully. If you interpret a variable incorrectly, you can generate nonsense results and never realize it. So before you start coding, you'll need to get familiar with the NSFG codebook, which describes every variable.\n",
    "\n",
    "Here is the documentation from the NSFG codebook for \"BIRTHWGT_OZ1\":\n",
    "\n",
    "birthwgt_oz1 codebook\n",
    "\n",
    "How many respondents refused to answer this question?\n",
    "\n",
    "Possible Answers\n",
    "\n",
    "    1\n",
    "    1\n",
    "    35\n",
    "    2\n",
    "    48-49\n",
    "    3\n",
    "    2967\n",
    "    4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93eabf1-65dc-426f-b427-82ecb5b0e1f2",
   "metadata": {},
   "source": [
    "<img src='https://assets.datacamp.com/production/repositories/4025/datasets/0d2a0c18b63f3ddf056858c145a6bdc022d8656c/Screenshot%202019-03-31%2019.16.14.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8e2a5c-a41c-4d13-bdba-91f38fcac76e",
   "metadata": {},
   "source": [
    "## Exploring the NSFG data\n",
    "\n",
    "To get the number of rows and columns in a DataFrame, you can read its shape attribute.\n",
    "\n",
    "To get the column names, you can read the columns attribute. The result is an Index, which is a Pandas data structure that is similar to a list. Let's begin exploring the NSFG data! It has been pre-loaded for you into a DataFrame called nsfg.\n",
    "Instructions 1/4\n",
    "25 XP\n",
    "\n",
    "    Question 1\n",
    "    Calculate the number of rows and columns in the DataFrame nsfg.\n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    Display the names of the columns in nsfg.\n",
    "    \n",
    "    \n",
    "    Question 3\n",
    "    Select the column 'birthwgt_oz1' and assign it to a new variable called ounces.\n",
    "    \n",
    "    \n",
    "    Question 4\n",
    "    Display the first 5 elements of ounces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9de85-5247-45b2-befd-9df80ce01a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of rows and columns\n",
    "nsfg.shape\n",
    "\n",
    "# Display the names of the columns\n",
    "nsfg.columns\n",
    "\n",
    "# Select column birthwgt_oz1: ounces\n",
    "ounces = nsfg['birthwgt_oz1']\n",
    "\n",
    "# Print the first 5 elements of ounces\n",
    "print(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6d8f0-56e5-4ba5-affb-901c829fe157",
   "metadata": {},
   "source": [
    "## Clean and Validate\n",
    "\n",
    "\n",
    "\n",
    "In the previous lesson, we read data from the National Survery of Family Growth and selected a column from a DataFrame.  [In this lesson, we'll check for errors and prepare the data for analysis].  We'll use the same DF we used in the previous lesson - nsfg, which contains one row for each pregnancy  in the survey.  We'll select the variable \"birthwgt_lb1\", which contains the pound part of birth weight, and assign it to pounds.  And \"birthwgt_oz1\" contains the ounce part of birth weight, so we'll assign that to ounces.  \n",
    "\n",
    "[Before we do anything with this data, we have to validate it].  One part of validation is confirming that we are interpreting the data correctly.  We can use the \"df.value_counts()\" method to see what values appear in pounds and how many times each value appears.  By default, the results are sorted with the most frequent value first, so we use \".sort_index()\" method to sort them by value instead (?? You mean use \"df.sort_values()\" method), with the lightest babies first and heaviest babies last.  As we'd expect, the most frequent values are 6-8 pounds, but there are some very light babies, a few very heavy babies, and two values, 98 and 99, that indicate missing data.  We can validate the results by comparing them to the codebook, which lists the values and their frequencies.  The results here agree with the codebook (__He means the data range is okay with documentation, go back the chack data processing with Pandas course or data cleaning course I guess and re-study it__), so we have some confidence that we are reading and interpreting the data correctly.  \n",
    "\n",
    "Another way to validate the data in with \"df.describe()\" method, which computes summary statistics like mean, standard deviation, min, and max (__But be careful with data type and range, as value based categories will appear min, max, mean statistic summary__).  Here we have the results for pounds.  The \"count\" is the number of values, The \"minimum\" and \"maximum\" values are 0 and 99 (Here the 98 and 99 are actually not real values, but specific category labels to represent value missing or bad things), and the 50th percentile, which is the [median] (Why based on statistic knowledge, sometime we don't use avg but use median instead?   {__Why median is used instead of average?__\n",
    "The mean is the most frequently used measure of central tendency because it uses all values in the data set to give you an average. For data from skewed distributions, the median is better than the mean because it isn't influenced by extremely large values.}   [][Google this topic], and I think one of the course talked about this topic), is 7.  \n",
    "\n",
    "The mean is about 8.05, but that doesn't mean much because it includes the special values 98 and 99.  Before we can really compute the mean, we have to replace those values with NaN to represent missing data.  The \"df.replace()\" method does what we want; it takes a list of values we want to replace and the values we want to replace them with.  The \"np.nan\" means we are getting the special value NaN form the NumPy library.  __The result from the \"df.replace()\" method is a new Series, whcih we assign back to replace its origin__.  Remember that the mean of the original Series was about 8.05 pounds.  The mean of the new Series is about 6.7 pounds.  It makes a big difference when you remove a few 98 and 99 pounds values.  \n",
    "\n",
    "[Instead of making a new Series, you can call \"df.replace(inplace=True)\" with \"replace=True\", which modifies the existing Series in place, that is without making a copy].  Here's what that look like for ounces.  Since we didn't make a new Series, we don't have to assign it back to its origin.  \n",
    "\n",
    "\n",
    "Now say we want to combine pounds and ounces into a single Series that contains total birth weight.  Arithmetic operators work with Series objects; so to convert from ounces to pounds, we can divide by 16 (there are 16 ounces in a pound).  Then we can add the two Series objects to get the total (Compare the calculation difference between SQL and Pandas, and recall in which course we learned such topic, re-study it and [][Google this topic]).  And here are the results.  The refreshed more accurate values are mean 7.1 pounds, which is little more than what we got before we added in the ounces part.  [Now we are close to answering our original question, the average birth weight for babiesin the USA] (__See, we need to check its distribution, cause the median will be more representive than mean in the skewed distribution__[][Google charm]).  But as we'll see in the next lesson, we're not there yet.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227064a5-a140-41af-904a-2778cdf419d7",
   "metadata": {},
   "source": [
    "## The values are based on how hard you are thinking and how hard you are pursuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d95d335-d8b3-4106-bb23-3a0b5f4089c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   caseid  outcome  birthwgt_lb1  birthwgt_oz1  prglngth  nbrnaliv  agecon  \\\n",
      "0   60418        1           5.0           4.0        40       1.0    2000   \n",
      "1   60418        1           4.0          12.0        36       1.0    2291   \n",
      "2   60418        1           5.0           4.0        36       1.0    3241   \n",
      "3   60419        6           NaN           NaN        33       NaN    3650   \n",
      "4   60420        1           8.0          13.0        41       1.0    2191   \n",
      "\n",
      "   agepreg  hpagelb  wgt2013_2015  Total_weight_pounds  \n",
      "0   2075.0     22.0   3554.964843               5.2500  \n",
      "1   2358.0     25.0   3554.964843               4.7500  \n",
      "2   3308.0     52.0   3554.964843               5.2500  \n",
      "3      NaN      NaN   2484.535358                  NaN  \n",
      "4   2266.0     24.0   2903.782914               8.8125  \n",
      "\n",
      "\n",
      "39    2384\n",
      "40    1311\n",
      "38     755\n",
      "37     432\n",
      "41     422\n",
      "Name: prglngth, dtype: int64\n",
      "\n",
      "\n",
      "48    1\n",
      "45    3\n",
      "46    3\n",
      "0     7\n",
      "23    7\n",
      "Name: prglngth, dtype: int64\n",
      "\n",
      "\n",
      "0      7\n",
      "1     11\n",
      "2     50\n",
      "3    102\n",
      "4    274\n",
      "Name: prglngth, dtype: int64\n",
      "count    6390.000000\n",
      "mean        6.703286\n",
      "std         1.429265\n",
      "min         0.000000\n",
      "25%         6.000000\n",
      "50%         7.000000\n",
      "75%         8.000000\n",
      "max        17.000000\n",
      "Name: birthwgt_lb1, dtype: float64\n",
      "count    6390.000000\n",
      "mean        6.703286\n",
      "std         1.429265\n",
      "min         0.000000\n",
      "25%         6.000000\n",
      "50%         7.000000\n",
      "75%         8.000000\n",
      "max        17.000000\n",
      "Name: birthwgt_lb1, dtype: float64\n",
      "\n",
      "\n",
      "count    6390.000000\n",
      "mean        7.153267\n",
      "std         1.485002\n",
      "min         0.000000\n",
      "25%         6.375000\n",
      "50%         7.187500\n",
      "75%         8.000000\n",
      "max        17.937500\n",
      "Name: Total_weight_pounds, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(df['prglngth'].value_counts()[:5])\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(df['prglngth'].value_counts().sort_values()[:5])\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(df['prglngth'].value_counts().sort_index()[:5])    # I know the instructor is wrong about this function\n",
    "\n",
    "print(df['birthwgt_lb1'].describe())\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "df['birthwgt_lb1'] = df['birthwgt_lb1'].replace([98, 99], np.nan)\n",
    "df['birthwgt_lb1'].replace('NaN', np.nan, inplace=True)   # =========================================================\n",
    "\n",
    "print(df['birthwgt_lb1'].describe())\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "df['Total_weight_pounds'] = df['birthwgt_lb1'] + df['birthwgt_oz1']/16   # ==========================================\n",
    "\n",
    "print(df['Total_weight_pounds'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ec24b-55cb-4621-93ba-f9e7e61121bc",
   "metadata": {},
   "source": [
    "## Validate a variable\n",
    "\n",
    "In the NSFG dataset, the variable 'outcome' encodes the outcome of each pregnancy as shown below:\n",
    "value \tlabel\n",
    "1 \tLive birth\n",
    "2 \tInduced abortion\n",
    "3 \tStillbirth\n",
    "4 \tMiscarriage\n",
    "5 \tEctopic pregnancy\n",
    "6 \tCurrent pregnancy\n",
    "\n",
    "The nsfg DataFrame has been pre-loaded for you. Explore it in the IPython Shell and use the methods Allen showed you in the video to answer the following question: How many pregnancies in this dataset ended with a live birth?\n",
    "Instructions\n",
    "50 XP\n",
    "Possible Answers\n",
    "\n",
    "    6489\n",
    "    9538\n",
    "    1469\n",
    "    6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c32ea-a5d6-4742-b010-ee99f0e45eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [1]:\n",
    "nsfg['outcome'].count_values()\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 72, in exceptionCatcher\n",
    "    raise exception\n",
    "  File \"<stdin>\", line 3361, in run_ast_nodes\n",
    "    if (await self.run_code(code, result,  async_=asy)):\n",
    "  File \"<stdin>\", line 3458, in run_code\n",
    "    self.showtraceback(running_compiled_code=True)\n",
    "  File \"<stdin>\", line 2066, in showtraceback\n",
    "    self._showtraceback(etype, value, stb)\n",
    "  File \"<stdin>\", line 72, in exceptionCatcher\n",
    "    raise exception\n",
    "  File \"<stdin>\", line 3441, in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "    nsfg['outcome'].count_values()\n",
    "  File \"<stdin>\", line 5487, in __getattr__\n",
    "    return object.__getattribute__(self, name)\n",
    "AttributeError: 'Series' object has no attribute 'count_values'\n",
    "In [2]:\n",
    "nsfg['outcome'].value_counts()   # ==================================================================================\n",
    "Out[2]:                          # Its value_counts() NOT count_values()\n",
    "\n",
    "1    6489\n",
    "4    1469\n",
    "2     947\n",
    "6     249\n",
    "5     118\n",
    "3      86\n",
    "Name: outcome, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb48a8b-910b-4e1d-b0d7-271329302172",
   "metadata": {},
   "source": [
    "## Clean a variable\n",
    "\n",
    "In the NSFG dataset, the variable 'nbrnaliv' records the number of babies born alive at the end of a pregnancy.\n",
    "\n",
    "If you use .value_counts() to view the responses, you'll see that the value 8 appears once, and if you consult the codebook, you'll see that this value indicates that the respondent refused to answer the question.\n",
    "\n",
    "Your job in this exercise is to replace this value with np.nan. Recall from the video how Allen replaced the values 98 and 99 in the ounces column using the .replace() method:\n",
    "\n",
    "ounces.replace([98, 99], np.nan, inplace=True)\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    In the 'nbrnaliv' column, replace the value 8, in place, with the special value NaN.\n",
    "    Confirm that the value 8 no longer appears in this column by printing the values and their frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c44f2-649e-40e4-9363-1783d988d381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f4272-e304-44ed-ae47-4d9cd77563d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c2ac4-132a-4028-99cc-5aa1058238df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810c047-b15d-49b3-aaca-4bfc5c793157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d12adb-a8eb-4fe9-b50e-46428edbb54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38cb4cc-5b53-451d-9e7c-07794c9d086e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce61cab-5478-4441-9dca-713002a32824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e36561-9a33-454f-a41f-72e2ad38a9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782107a-f3d6-4431-8605-ec34a4a1c6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e1a344-b22d-4d12-8b94-04e135341b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b4cd4-7252-474c-9e94-9daf73648eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470994f-a86f-4d51-8072-29fa854e6ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50d75f-60a0-46aa-9afc-5537f128d34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1387e6-f280-4725-8d8c-5043786e044d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c502a5c2-5fef-49ce-a068-7f68b837ee5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2d772-b2d0-4aef-a42b-874e3a1e5baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf27904-de41-4236-bbd1-d4f69917253f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bcde61-cc8c-4176-b3e8-d06bc860877f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3cc0f2-eded-47e5-800f-4d70733e9705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee07d38-6570-4550-a9f8-a6b0027a0a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd175177-69e8-4027-a3b4-c12003ada6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eff5f0-3c6b-4b03-ac27-bd615bd9c051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26851488-4223-487c-b882-807b1edb4e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1b275-5882-44b4-af85-37bcdec54bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccb2d9-df9b-4ea8-84d1-ccfb0295488a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1c185-78a1-4b4a-9a03-6fc99fc4c3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb84e73-ccd1-401a-8956-c3e9bf6346fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e78cad-d7fe-4a1a-b152-2d9393b9b471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24163d22-7069-421e-bcc7-7dd910b347f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14592c4-8fdc-4825-9a5d-74ffa052a24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206e7e0-e142-4ba9-b565-a5ddc24be2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5f8d6-7829-4aef-a0b1-3cc671a8f535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f993e-90a4-40af-a9d2-1d5597e3db34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed43ebb-7d27-463e-b757-b9a916df6998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ae618-1bbc-40bc-a0b0-249717cf5b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0286bc-2980-43d8-ad9a-a9ae7cb691a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132ac3b-bdec-4195-b7c0-4a25cffa3184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd6348-d942-420a-8fc1-4136ffb84cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33402d0-97f7-4fa2-9fc8-6a596dcf8f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef0c34-11cb-4f1e-8d05-42dba784c7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167184bb-769a-47df-8b85-e3a28e6349b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c16bfb-37f1-4156-828c-18f0b35fba11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34fb3d5-7148-4fba-9a9d-c0ef40d5edfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5b2c4-9ce4-4abe-8b44-4a65c167bb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b72d13-7547-4335-8a47-776c006b5433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48609729-d9d1-4b3e-93de-819c4a7a46f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014e506-cd6a-43e5-97af-7ddfda6c78e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f24d8-4591-4d76-97aa-f46234d8489b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a6bad-ad55-4698-aee1-4729c57725a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a593d50-6a43-4a22-b4e3-b8a5b093576a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffeb7a0-e079-4cac-94ca-b3687bebce59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6610a6-b75d-4e7c-ae89-a5e1b90eb9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78dbbbc-2ec7-4b45-a3bc-e5744862bb22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
