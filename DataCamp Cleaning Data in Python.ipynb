{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdb6c41-92b9-47b2-b660-7e6a4b1e24c2",
   "metadata": {},
   "source": [
    "## Cleaning Data in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055a7c9-8970-4132-829c-2b27d95c641c",
   "metadata": {},
   "source": [
    "## Course Description\n",
    "\n",
    "It's commonly said that data scientists spend 80% of their time cleaning and manipulating data and only 20% of their time analyzing it. The time spent cleaning is vital since analyzing dirty data can lead you to draw inaccurate conclusions. Data cleaning is an essential task in data science. Without properly cleaned data, the results of any data analysis or machine learning model could be inaccurate. In this course, you will learn how to identify, diagnose, and treat a variety of data cleaning problems in Python, ranging from simple to advanced. You will deal with improper data types, check that your data is in the correct range, handle missing data, perform record linkage, and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef6cb7-259a-431e-90c6-1daf990df19d",
   "metadata": {},
   "source": [
    "##  Common data problems\n",
    "Free\n",
    "0%\n",
    "\n",
    "In this chapter, you'll learn how to overcome some of the most common dirty data problems. You'll convert data types, apply range constraints to remove future data points, and remove duplicated data points to avoid double-counting.\n",
    "\n",
    "    Data type constraints    50 xp\n",
    "    Common data types    100 xp\n",
    "    Numeric data or ... ?    100 xp\n",
    "    Summing strings and concatenating numbers    100 xp\n",
    "    Data range constraints    50 xp\n",
    "    Tire size constraints    100 xp\n",
    "    Back to the future    100 xp\n",
    "    Uniqueness constraints    50 xp\n",
    "    How big is your subset?    50 xp\n",
    "    Finding duplicates   100 xp\n",
    "    Treating duplicates    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781858e-0a46-4241-98dd-6547f3c63dc5",
   "metadata": {},
   "source": [
    "##  Text and categorical data problems\n",
    "0%\n",
    "\n",
    "Categorical and text data can often be some of the messiest parts of a dataset due to their unstructured nature. In this chapter, you’ll learn how to fix whitespace and capitalization inconsistencies in category labels, collapse multiple categories into one, and reformat strings for consistency.\n",
    "\n",
    "    Membership constraints    50 xp\n",
    "    Members only    100 xp\n",
    "    Finding consistency    100 xp\n",
    "    Categorical variables    50 xp\n",
    "    Categories of errors    100 xp\n",
    "    Inconsistent categories    100 xp\n",
    "    Remapping categories    100 xp\n",
    "    Cleaning text data    50 xp\n",
    "    Removing titles and taking names    100 xp\n",
    "    Keeping it descriptive    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf42f6f-f930-4e9a-9fd7-7aebf5c266a3",
   "metadata": {},
   "source": [
    "##  Advanced data problems\n",
    "0%\n",
    "\n",
    "In this chapter, you’ll dive into more advanced data cleaning problems, such as ensuring that weights are all written in kilograms instead of pounds. You’ll also gain invaluable skills that will help you verify that values have been added correctly and that missing values don’t negatively impact your analyses.\n",
    "\n",
    "    Uniformity    50 xp\n",
    "    Ambiguous dates    50 xp\n",
    "    Uniform currencies    100 xp\n",
    "    Uniform dates    100 xp\n",
    "    Cross field validation    50 xp\n",
    "    Cross field or no cross field?    100 xp\n",
    "    How's our data integrity?    100 xp\n",
    "    Completeness    50 xp\n",
    "    Is this missing at random?    50 xp\n",
    "    Missing investors    100 xp\n",
    "    Follow the money    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6a59e4-6b35-408c-8fb3-1bf98ad897de",
   "metadata": {},
   "source": [
    "##  Record linkage\n",
    "0%\n",
    "\n",
    "Record linkage is a powerful technique used to merge multiple datasets together, used when values have typos or different spellings. In this chapter, you'll learn how to link records by calculating the similarity between strings—you’ll then use your new skills to join two restaurant review datasets into one clean master dataset.\n",
    "\n",
    "    Comparing strings    50 xp\n",
    "    Minimum edit distance    50 xp\n",
    "    The cutoff point    100 xp\n",
    "    Remapping categories II    100 xp\n",
    "    Generating pairs    50 xp\n",
    "    To link or not to link?    100 xp\n",
    "    Pairs of restaurants    100 xp\n",
    "    Similar restaurants    100 xp\n",
    "    Linking DataFrames    50 xp\n",
    "    Getting the right index    50 xp\n",
    "    Linking them together!    100 xp\n",
    "    Congratulations!    50 xp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094813d4-e269-4a00-8837-ebe1ea5fb63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa37edc2-e0fe-4481-a3d7-c2f29bf3dbee",
   "metadata": {},
   "source": [
    "## Data type constraints\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**The institutor's name is Adel, he'll be our host as we learn how to clean data in Python.  \n",
    "\n",
    "# In this course, we're going to understand how to diagnose different problems in our data and how they can come up during out workflow.  We will also understand the side effects of not treating our data correctly.  And various ways to address different types of dirty data.  \n",
    "\n",
    "\n",
    "In this chapter, we're going to discuss the most common data problems you may encounter and how to address them.  \n",
    "\n",
    "# To understand why we need to clean data, lets remind ourselves of the data science workflow.  In a typical data science workflow, we usually access our raw data, explore and process it, develop insights using visualizations or predictive models, and finally report these insights with dashboards or reports.  \n",
    "\n",
    "\n",
    "Access Data --> Explore and Process Data --> Extract Insights --> Report Insights\n",
    "\n",
    "\n",
    "# Dirty data can appear because of duplicate values, miss-spellings, data type parsing errors and legacy systems.  \n",
    "Without making sure that data is properly clearned in the exploration and processing phase, we will surely compromise the insights and reports subsequently generated.  As the old adage says, garbage in garbage out.  \n",
    "\n",
    "\n",
    "When working with data, there are various types that we may encounter along the way.  We could be working with text data, integers, decimals, dates, zip codes, and others.  Luckily, Python has specific data type objects for various data typeat you're probably familiar with by now.  This makes it much easier to manipulate these various data types in Python.  \n",
    "    \n",
    "    Text data, Integers, Decimals, Binary, Dates, Categories\n",
    "    str, int, float, bool, datetime, cateory\n",
    "\n",
    "# As such, before preparing to analyze and extract insights from our data, we need to make sure our variables have the correctdata types, other wise we risk compromising our anaysis.  Lets take a look at the following example.  \n",
    "\n",
    "Belwo is a head od a DF containing revenue generated and quantity of items sold for a sales order.  We want to \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53a2fc-1b2d-48da-9110-a923c4faea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales.csv')\n",
    "\n",
    "print(sales.head())\n",
    "\n",
    "\n",
    "---------------------------------------------\n",
    "  SalesOrderId  | Revenue     | Quantity\n",
    "0        43659  |     23153$  |       12\n",
    "1        43660  |      1457$  |        2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c075397b-8c4e-45ec-b130-394c52927157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602a61b-bb36-4dbc-8468-49d8ed27977b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88e088-53c6-4ac8-a6b0-d0e683629b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51eae4-451e-407a-9189-bc0ca9e6a412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c926df5-24ba-46f6-9c88-25df7a76b16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052eaea-8c07-4458-a688-9d69ac88978d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
